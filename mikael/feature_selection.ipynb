{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Master import MasterDataframes\n",
    "\n",
    "\n",
    "# Data handling\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Helper functions\n",
    "from functions import get_days_sinse_beginning_of_year, get_seconds_of_day\n",
    "\n",
    "# Types handling\n",
    "import numpy as np\n",
    "\n",
    "# Data science\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.feature_selection import SelectFromModel, RFECV\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "\n",
    "# Machine learning tool\n",
    "import xgboost as xgb\n",
    "# Optimization / feature engineering tools\n",
    "import optuna\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Smart options\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = MasterDataframes().prep_dataset_x_y(\"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-29 11:54:06,253] A new study created in memory with name: regression\n",
      "[I 2023-09-29 11:54:08,921] Trial 0 finished with value: 552225973.8416195 and parameters: {'max_depth': 10, 'learning_rate': 0.6403698866093191, 'n_estimators': 729, 'min_child_weight': 10, 'gamma': 0.10379618775652646, 'subsample': 0.11332722970223123, 'colsample_bytree': 0.21140713077007542, 'reg_alpha': 0.3082468104568156, 'reg_lambda': 0.8284468801827363, 'random_state': 471}. Best is trial 0 with value: 552225973.8416195.\n",
      "[I 2023-09-29 11:54:10,691] Trial 1 finished with value: 483.1535115596932 and parameters: {'max_depth': 5, 'learning_rate': 0.6903092636296524, 'n_estimators': 689, 'min_child_weight': 5, 'gamma': 0.3606264981914766, 'subsample': 0.3481328409035814, 'colsample_bytree': 0.48115730538457707, 'reg_alpha': 0.8477706285988587, 'reg_lambda': 0.6234714224662702, 'random_state': 350}. Best is trial 1 with value: 483.1535115596932.\n",
      "[I 2023-09-29 11:54:12,254] Trial 2 finished with value: 232.08508614026883 and parameters: {'max_depth': 4, 'learning_rate': 0.2852265866543356, 'n_estimators': 786, 'min_child_weight': 10, 'gamma': 0.7490150218087984, 'subsample': 0.37689677999517407, 'colsample_bytree': 0.30078578813275253, 'reg_alpha': 0.7495884876705632, 'reg_lambda': 0.018221927152124756, 'random_state': 864}. Best is trial 2 with value: 232.08508614026883.\n",
      "[I 2023-09-29 11:54:13,370] Trial 3 finished with value: 1347.5048269586978 and parameters: {'max_depth': 5, 'learning_rate': 0.6307590893099109, 'n_estimators': 468, 'min_child_weight': 7, 'gamma': 0.35746931638913687, 'subsample': 0.18140649287660604, 'colsample_bytree': 0.13949044881967448, 'reg_alpha': 0.8839092304756535, 'reg_lambda': 0.7057822954115224, 'random_state': 832}. Best is trial 2 with value: 232.08508614026883.\n",
      "[I 2023-09-29 11:54:16,245] Trial 4 finished with value: 244.6783132174886 and parameters: {'max_depth': 7, 'learning_rate': 0.6264704385875671, 'n_estimators': 636, 'min_child_weight': 8, 'gamma': 0.10181861060324204, 'subsample': 0.787634762883832, 'colsample_bytree': 0.6789778094304325, 'reg_alpha': 0.07955753214560023, 'reg_lambda': 0.08613543120869775, 'random_state': 870}. Best is trial 2 with value: 232.08508614026883.\n",
      "[I 2023-09-29 11:54:19,246] Trial 5 finished with value: 202.1125102181745 and parameters: {'max_depth': 8, 'learning_rate': 0.3028485589774628, 'n_estimators': 466, 'min_child_weight': 5, 'gamma': 0.16758273702659238, 'subsample': 0.6944398328364936, 'colsample_bytree': 0.7707175360031195, 'reg_alpha': 0.3746694743356348, 'reg_lambda': 0.24822374317653367, 'random_state': 801}. Best is trial 5 with value: 202.1125102181745.\n",
      "[I 2023-09-29 11:54:23,325] Trial 6 finished with value: 178.2728758034034 and parameters: {'max_depth': 10, 'learning_rate': 0.12002127026364758, 'n_estimators': 464, 'min_child_weight': 7, 'gamma': 0.3726341103066115, 'subsample': 0.7915134770031012, 'colsample_bytree': 0.9055401413732296, 'reg_alpha': 0.9989398078203087, 'reg_lambda': 0.5693766626176643, 'random_state': 620}. Best is trial 6 with value: 178.2728758034034.\n",
      "[I 2023-09-29 11:54:24,809] Trial 7 finished with value: 1595.5844640158514 and parameters: {'max_depth': 2, 'learning_rate': 0.9086065207193744, 'n_estimators': 989, 'min_child_weight': 9, 'gamma': 0.25324158679627295, 'subsample': 0.20296920100273488, 'colsample_bytree': 0.6533490622903789, 'reg_alpha': 0.6982867942124408, 'reg_lambda': 0.18440521016373465, 'random_state': 202}. Best is trial 6 with value: 178.2728758034034.\n",
      "[I 2023-09-29 11:54:26,464] Trial 8 finished with value: 194.94856889780812 and parameters: {'max_depth': 4, 'learning_rate': 0.040623177776320574, 'n_estimators': 770, 'min_child_weight': 10, 'gamma': 0.1212354129356383, 'subsample': 0.9946738515495086, 'colsample_bytree': 0.6832335069080948, 'reg_alpha': 0.48388604273888297, 'reg_lambda': 0.9288643447829837, 'random_state': 953}. Best is trial 6 with value: 178.2728758034034.\n",
      "[I 2023-09-29 11:54:27,815] Trial 9 finished with value: 1113.6736921406018 and parameters: {'max_depth': 7, 'learning_rate': 0.8842621253490813, 'n_estimators': 418, 'min_child_weight': 6, 'gamma': 0.7830495670391957, 'subsample': 0.3796722051697328, 'colsample_bytree': 0.2786432092288996, 'reg_alpha': 0.34329729067268977, 'reg_lambda': 0.7333504952196509, 'random_state': 125}. Best is trial 6 with value: 178.2728758034034.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 17827.29%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=10, test_size=0.20, groups=None)\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        \"objective\": \"reg:linear\",\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 1.0),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 1000),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.01, 1.0),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.01, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.01, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.01, 1.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.01, 1.0),\n",
    "        \"random_state\": trial.suggest_int(\"random_state\", 1, 1000),\n",
    "    }\n",
    "    model = xgb.XGBRegressor(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\", study_name=\"regression\")\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "model = xgb.XGBRegressor(**study.best_params)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "accuracy = mean_absolute_error(y_test, y_pred)\n",
    "print(\"MAE: %.2f%%\" % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best: 180.09733287984827\n",
      "Thresh=0.0016273983, n=73, MAE: 180.09733287984827, Best: 180.09733287984827\n",
      "Thresh=0.0019661684, n=72, MAE: 181.56535625984182, Best: 180.09733287984827\n",
      "Thresh=0.0023614739, n=71, MAE: 180.76675521200988, Best: 180.09733287984827\n",
      "Thresh=0.002474928, n=70, MAE: 180.99984651742383, Best: 180.09733287984827\n",
      "Thresh=0.0025197142, n=69, MAE: 182.10846923070955, Best: 180.09733287984827\n",
      "Thresh=0.0026132972, n=68, MAE: 183.51906247248445, Best: 180.09733287984827\n",
      "Thresh=0.0027077012, n=67, MAE: 181.77093489279997, Best: 180.09733287984827\n",
      "New best: 178.9970749403461\n",
      "Thresh=0.0029031972, n=66, MAE: 178.9970749403461, Best: 178.9970749403461\n",
      "Thresh=0.0030150632, n=65, MAE: 180.3222760848616, Best: 178.9970749403461\n",
      "New best: 178.20908320870808\n",
      "Thresh=0.0031922213, n=64, MAE: 178.20908320870808, Best: 178.20908320870808\n",
      "New best: 178.06597252851486\n",
      "Thresh=0.0033383314, n=63, MAE: 178.06597252851486, Best: 178.06597252851486\n",
      "Thresh=0.0033546565, n=62, MAE: 182.18303751946763, Best: 178.06597252851486\n",
      "Thresh=0.0033714164, n=61, MAE: 179.37681756274617, Best: 178.06597252851486\n",
      "New best: 177.68337965206555\n",
      "Thresh=0.003405309, n=60, MAE: 177.68337965206555, Best: 177.68337965206555\n",
      "Thresh=0.0034309535, n=59, MAE: 180.4544647695175, Best: 177.68337965206555\n",
      "Thresh=0.0035643955, n=58, MAE: 181.39458044608367, Best: 177.68337965206555\n",
      "Thresh=0.0038330192, n=57, MAE: 179.44799024715894, Best: 177.68337965206555\n",
      "Thresh=0.0039174953, n=56, MAE: 180.34203238632543, Best: 177.68337965206555\n",
      "Thresh=0.003992796, n=55, MAE: 178.79549282725134, Best: 177.68337965206555\n",
      "New best: 177.1482451355037\n",
      "Thresh=0.0040013427, n=54, MAE: 177.1482451355037, Best: 177.1482451355037\n",
      "Thresh=0.004047841, n=53, MAE: 180.14628586188462, Best: 177.1482451355037\n",
      "Thresh=0.0040765274, n=52, MAE: 181.30681535977308, Best: 177.1482451355037\n",
      "Thresh=0.004144105, n=51, MAE: 180.8639284197242, Best: 177.1482451355037\n",
      "Thresh=0.0041781696, n=50, MAE: 178.29057215752644, Best: 177.1482451355037\n",
      "Thresh=0.0041816877, n=49, MAE: 180.121250782192, Best: 177.1482451355037\n",
      "Thresh=0.0041870247, n=48, MAE: 179.45721063052443, Best: 177.1482451355037\n",
      "Thresh=0.004207796, n=47, MAE: 182.18028559915717, Best: 177.1482451355037\n",
      "Thresh=0.004243429, n=46, MAE: 181.67015313273674, Best: 177.1482451355037\n",
      "Thresh=0.0043992843, n=45, MAE: 180.12188813885197, Best: 177.1482451355037\n",
      "Thresh=0.004455633, n=44, MAE: 177.17889626531414, Best: 177.1482451355037\n",
      "Thresh=0.004511367, n=43, MAE: 179.49066984871715, Best: 177.1482451355037\n",
      "Thresh=0.0045893383, n=42, MAE: 178.93536164025605, Best: 177.1482451355037\n",
      "Thresh=0.004644364, n=41, MAE: 178.9220021043134, Best: 177.1482451355037\n",
      "Thresh=0.0046534548, n=40, MAE: 181.30182763389027, Best: 177.1482451355037\n",
      "Thresh=0.004701657, n=39, MAE: 180.88707284829928, Best: 177.1482451355037\n",
      "Thresh=0.004955734, n=38, MAE: 181.17099457165503, Best: 177.1482451355037\n",
      "Thresh=0.005070987, n=37, MAE: 180.76089633078684, Best: 177.1482451355037\n",
      "Thresh=0.0052010063, n=36, MAE: 179.99644308554704, Best: 177.1482451355037\n",
      "Thresh=0.005210357, n=35, MAE: 183.25466611348386, Best: 177.1482451355037\n",
      "Thresh=0.005274337, n=34, MAE: 181.44237013930885, Best: 177.1482451355037\n",
      "Thresh=0.005432448, n=33, MAE: 183.11757853779832, Best: 177.1482451355037\n",
      "Thresh=0.0055784807, n=32, MAE: 179.14844993363664, Best: 177.1482451355037\n",
      "Thresh=0.0055794637, n=31, MAE: 183.71569910273521, Best: 177.1482451355037\n",
      "Thresh=0.0055945767, n=30, MAE: 180.32762677323305, Best: 177.1482451355037\n",
      "Thresh=0.0056232363, n=29, MAE: 186.54842507177196, Best: 177.1482451355037\n",
      "Thresh=0.0056272442, n=28, MAE: 186.46387981053556, Best: 177.1482451355037\n",
      "Thresh=0.00564509, n=27, MAE: 185.98572826588136, Best: 177.1482451355037\n",
      "Thresh=0.00578432, n=26, MAE: 186.02718978259526, Best: 177.1482451355037\n",
      "Thresh=0.0060957614, n=25, MAE: 184.86014528994275, Best: 177.1482451355037\n",
      "Thresh=0.006133968, n=24, MAE: 184.9454971655451, Best: 177.1482451355037\n",
      "Thresh=0.0063000876, n=23, MAE: 184.0617232951367, Best: 177.1482451355037\n",
      "Thresh=0.0063466164, n=22, MAE: 188.74997270161964, Best: 177.1482451355037\n",
      "Thresh=0.006347113, n=21, MAE: 189.1249209288156, Best: 177.1482451355037\n",
      "Thresh=0.0063643316, n=20, MAE: 190.2761320208727, Best: 177.1482451355037\n",
      "Thresh=0.006400454, n=19, MAE: 189.9677514463188, Best: 177.1482451355037\n",
      "Thresh=0.006545546, n=18, MAE: 192.01317815643588, Best: 177.1482451355037\n",
      "Thresh=0.0069780378, n=17, MAE: 194.30426923358436, Best: 177.1482451355037\n",
      "Thresh=0.0071835686, n=16, MAE: 192.15166996961838, Best: 177.1482451355037\n",
      "Thresh=0.007307068, n=15, MAE: 205.01802210721303, Best: 177.1482451355037\n",
      "Thresh=0.0077021094, n=14, MAE: 208.52696444896065, Best: 177.1482451355037\n",
      "Thresh=0.00833488, n=13, MAE: 210.78874060861378, Best: 177.1482451355037\n",
      "Thresh=0.0084903855, n=12, MAE: 218.31198205008104, Best: 177.1482451355037\n",
      "Thresh=0.009455711, n=11, MAE: 218.83183158723324, Best: 177.1482451355037\n",
      "Thresh=0.009829722, n=10, MAE: 219.7317804477071, Best: 177.1482451355037\n",
      "Thresh=0.011797003, n=9, MAE: 218.17841943495554, Best: 177.1482451355037\n",
      "Thresh=0.01186206, n=8, MAE: 220.58146042545937, Best: 177.1482451355037\n",
      "Thresh=0.015171097, n=7, MAE: 218.0662086516693, Best: 177.1482451355037\n",
      "Thresh=0.017891234, n=6, MAE: 228.5575244861751, Best: 177.1482451355037\n",
      "Thresh=0.021370199, n=5, MAE: 257.0215110602798, Best: 177.1482451355037\n",
      "Thresh=0.034297083, n=4, MAE: 258.1587951795735, Best: 177.1482451355037\n",
      "Thresh=0.03714141, n=3, MAE: 255.21179153139536, Best: 177.1482451355037\n",
      "Thresh=0.06616674, n=2, MAE: 247.53527370972068, Best: 177.1482451355037\n",
      "Thresh=0.46912682, n=1, MAE: 284.74889063406357, Best: 177.1482451355037\n"
     ]
    }
   ],
   "source": [
    "thresholds = np.sort(model.feature_importances_)\n",
    "best = accuracy\n",
    "for thresh in thresholds[int(len(thresholds)/4) : ]:\n",
    "    # select features using threshold\n",
    "    selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "    select_X_train = selection.transform(X_train)\n",
    "    # train model\n",
    "    selection_model = xgb.XGBRegressor(**study.best_params)\n",
    "    selection_model.fit(select_X_train, y_train)\n",
    "    # eval model\n",
    "    select_X_test = selection.transform(X_test)\n",
    "    y_pred = selection_model.predict(select_X_test)\n",
    "    \n",
    "    accuracy = mean_absolute_error(y_test, y_pred)\n",
    "    if best > accuracy:\n",
    "        best = accuracy\n",
    "        print(f\"New best: {best}\")\n",
    "    print(f\"Thresh={str(thresh)}, n={select_X_train.shape[1]}, MAE: {accuracy}, Best: {best}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TDT4173",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
