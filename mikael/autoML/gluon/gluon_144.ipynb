{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> prøver å gjenskape henning sin 143.</h3>\n",
    "<p><p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miksx/.pyenv/versions/3.10.12/envs/TDT4173/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/miksx/GitHub/Forest-Gump/mikael/autoML/gluon\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "from pipeline import Pipeline\n",
    "pipin = Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"ag_144_exstract_time_3_12\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_0 = pipin.get_data(\"A\")\n",
    "df2_0 = pipin.get_data(\"B\")\n",
    "df3_0 = pipin.get_data(\"C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sun_elevation:d', 'sun_elevation:d_45'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_columns = df1_0.select_dtypes(include='number').columns\n",
    "\n",
    "# Select columns with negative values, excluding datetime columns\n",
    "negative_columns = numeric_columns[(df1_0[numeric_columns] < 0).any()]\n",
    "negative_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miksx/GitHub/Forest-Gump/mikael/autoML/gluon/pipeline.py:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['consecutive_group'] = df.groupby(\n",
      "/Users/miksx/GitHub/Forest-Gump/mikael/autoML/gluon/pipeline.py:255: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"is_first_in_consecutive_group\"] = False\n",
      "/Users/miksx/GitHub/Forest-Gump/mikael/autoML/gluon/pipeline.py:272: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(columns=[\"consecutive_group\",\n",
      "/Users/miksx/GitHub/Forest-Gump/mikael/autoML/gluon/pipeline.py:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['consecutive_group'] = df.groupby(\n",
      "/Users/miksx/GitHub/Forest-Gump/mikael/autoML/gluon/pipeline.py:255: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"is_first_in_consecutive_group\"] = False\n",
      "/Users/miksx/GitHub/Forest-Gump/mikael/autoML/gluon/pipeline.py:272: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(columns=[\"consecutive_group\",\n",
      "/Users/miksx/GitHub/Forest-Gump/mikael/autoML/gluon/pipeline.py:252: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['consecutive_group'] = df.groupby(\n",
      "/Users/miksx/GitHub/Forest-Gump/mikael/autoML/gluon/pipeline.py:255: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"is_first_in_consecutive_group\"] = False\n",
      "/Users/miksx/GitHub/Forest-Gump/mikael/autoML/gluon/pipeline.py:272: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(columns=[\"consecutive_group\",\n"
     ]
    }
   ],
   "source": [
    "# remove_consecutive_measurments\n",
    "# 6/24\n",
    "# dette skal prøve å gjenskape henning sin\n",
    "df1_0 = pipin.remove_consecutive_measurments_new(df1_0, 3, 12)\n",
    "df2_0 = pipin.remove_consecutive_measurments_new(df2_0, 3, 12)\n",
    "df3_0 = pipin.remove_consecutive_measurments_new(df3_0, 3, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28405, 185) (19779, 185) (16819, 185)\n"
     ]
    }
   ],
   "source": [
    "print(df1_0.shape, df2_0.shape, df3_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute_humidity_2m:gm3</th>\n",
       "      <th>air_density_2m:kgm3</th>\n",
       "      <th>ceiling_height_agl:m</th>\n",
       "      <th>clear_sky_energy_1h:J</th>\n",
       "      <th>clear_sky_rad:W</th>\n",
       "      <th>cloud_base_agl:m</th>\n",
       "      <th>dew_or_rime:idx</th>\n",
       "      <th>dew_point_2m:K</th>\n",
       "      <th>diffuse_rad:W</th>\n",
       "      <th>diffuse_rad_1h:J</th>\n",
       "      <th>...</th>\n",
       "      <th>super_cooled_liquid_water:kgm2_45</th>\n",
       "      <th>t_1000hPa:K_45</th>\n",
       "      <th>total_cloud_cover:p_45</th>\n",
       "      <th>visibility:m_45</th>\n",
       "      <th>wind_speed_10m:ms_45</th>\n",
       "      <th>estimated_45</th>\n",
       "      <th>observed_45</th>\n",
       "      <th>day_of_year_45</th>\n",
       "      <th>hour_45</th>\n",
       "      <th>pv_measurement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28398.000000</td>\n",
       "      <td>28398.000000</td>\n",
       "      <td>21599.000000</td>\n",
       "      <td>2.839800e+04</td>\n",
       "      <td>28398.000000</td>\n",
       "      <td>25705.000000</td>\n",
       "      <td>28398.000000</td>\n",
       "      <td>28398.000000</td>\n",
       "      <td>28398.000000</td>\n",
       "      <td>2.839800e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>28398.000000</td>\n",
       "      <td>28398.000000</td>\n",
       "      <td>28398.000000</td>\n",
       "      <td>28398.000000</td>\n",
       "      <td>28398.000000</td>\n",
       "      <td>28398.000000</td>\n",
       "      <td>28398.000000</td>\n",
       "      <td>28398.000000</td>\n",
       "      <td>28398.000000</td>\n",
       "      <td>28405.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.774164</td>\n",
       "      <td>1.247887</td>\n",
       "      <td>2965.184326</td>\n",
       "      <td>6.616430e+05</td>\n",
       "      <td>183.861374</td>\n",
       "      <td>1716.823608</td>\n",
       "      <td>0.040003</td>\n",
       "      <td>277.130371</td>\n",
       "      <td>50.524544</td>\n",
       "      <td>1.816869e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056205</td>\n",
       "      <td>281.027374</td>\n",
       "      <td>73.299736</td>\n",
       "      <td>32215.990234</td>\n",
       "      <td>3.012018</td>\n",
       "      <td>0.107296</td>\n",
       "      <td>0.892704</td>\n",
       "      <td>178.688887</td>\n",
       "      <td>11.456828</td>\n",
       "      <td>756.691448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.790600</td>\n",
       "      <td>0.035813</td>\n",
       "      <td>2617.824707</td>\n",
       "      <td>8.910664e+05</td>\n",
       "      <td>248.142624</td>\n",
       "      <td>1848.394043</td>\n",
       "      <td>0.195969</td>\n",
       "      <td>6.640284</td>\n",
       "      <td>65.809540</td>\n",
       "      <td>2.341651e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105999</td>\n",
       "      <td>6.505377</td>\n",
       "      <td>34.046993</td>\n",
       "      <td>17595.304688</td>\n",
       "      <td>1.753547</td>\n",
       "      <td>0.309495</td>\n",
       "      <td>0.309495</td>\n",
       "      <td>90.771195</td>\n",
       "      <td>6.724242</td>\n",
       "      <td>1239.248231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.145000</td>\n",
       "      <td>27.799999</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>250.899994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>259.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>265.299988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>1.223000</td>\n",
       "      <td>1099.900024</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>560.900024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>272.399994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>276.200012</td>\n",
       "      <td>51.500000</td>\n",
       "      <td>16139.324219</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.500000</td>\n",
       "      <td>1.245000</td>\n",
       "      <td>1918.599976</td>\n",
       "      <td>1.249152e+05</td>\n",
       "      <td>34.599998</td>\n",
       "      <td>1105.900024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>277.799988</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>6.555970e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>281.200012</td>\n",
       "      <td>92.599998</td>\n",
       "      <td>35709.046875</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>92.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.700000</td>\n",
       "      <td>1.271000</td>\n",
       "      <td>4088.800049</td>\n",
       "      <td>1.186012e+06</td>\n",
       "      <td>333.675018</td>\n",
       "      <td>2057.899902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>282.200012</td>\n",
       "      <td>84.599998</td>\n",
       "      <td>3.041082e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>285.399994</td>\n",
       "      <td>99.900002</td>\n",
       "      <td>47349.250000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>969.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.500000</td>\n",
       "      <td>1.427000</td>\n",
       "      <td>12307.700195</td>\n",
       "      <td>3.004693e+06</td>\n",
       "      <td>834.799988</td>\n",
       "      <td>11688.700195</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>293.799988</td>\n",
       "      <td>336.700012</td>\n",
       "      <td>1.182250e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>303.299988</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>70518.203125</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>366.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>5733.420000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 185 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       absolute_humidity_2m:gm3  air_density_2m:kgm3  ceiling_height_agl:m  \\\n",
       "count              28398.000000         28398.000000          21599.000000   \n",
       "mean                   6.774164             1.247887           2965.184326   \n",
       "std                    2.790600             0.035813           2617.824707   \n",
       "min                    0.700000             1.145000             27.799999   \n",
       "25%                    4.500000             1.223000           1099.900024   \n",
       "50%                    6.500000             1.245000           1918.599976   \n",
       "75%                    8.700000             1.271000           4088.800049   \n",
       "max                   17.500000             1.427000          12307.700195   \n",
       "\n",
       "       clear_sky_energy_1h:J  clear_sky_rad:W  cloud_base_agl:m  \\\n",
       "count           2.839800e+04     28398.000000      25705.000000   \n",
       "mean            6.616430e+05       183.861374       1716.823608   \n",
       "std             8.910664e+05       248.142624       1848.394043   \n",
       "min             0.000000e+00         0.000000         27.900000   \n",
       "25%             0.000000e+00         0.000000        560.900024   \n",
       "50%             1.249152e+05        34.599998       1105.900024   \n",
       "75%             1.186012e+06       333.675018       2057.899902   \n",
       "max             3.004693e+06       834.799988      11688.700195   \n",
       "\n",
       "       dew_or_rime:idx  dew_point_2m:K  diffuse_rad:W  diffuse_rad_1h:J  ...  \\\n",
       "count     28398.000000    28398.000000   28398.000000      2.839800e+04  ...   \n",
       "mean          0.040003      277.130371      50.524544      1.816869e+05  ...   \n",
       "std           0.195969        6.640284      65.809540      2.341651e+05  ...   \n",
       "min           0.000000      250.899994       0.000000      0.000000e+00  ...   \n",
       "25%           0.000000      272.399994       0.000000      0.000000e+00  ...   \n",
       "50%           0.000000      277.799988      17.900000      6.555970e+04  ...   \n",
       "75%           0.000000      282.200012      84.599998      3.041082e+05  ...   \n",
       "max           1.000000      293.799988     336.700012      1.182250e+06  ...   \n",
       "\n",
       "       super_cooled_liquid_water:kgm2_45  t_1000hPa:K_45  \\\n",
       "count                       28398.000000    28398.000000   \n",
       "mean                            0.056205      281.027374   \n",
       "std                             0.105999        6.505377   \n",
       "min                             0.000000      259.000000   \n",
       "25%                             0.000000      276.200012   \n",
       "50%                             0.000000      281.200012   \n",
       "75%                             0.100000      285.399994   \n",
       "max                             1.200000      303.299988   \n",
       "\n",
       "       total_cloud_cover:p_45  visibility:m_45  wind_speed_10m:ms_45  \\\n",
       "count            28398.000000     28398.000000          28398.000000   \n",
       "mean                73.299736     32215.990234              3.012018   \n",
       "std                 34.046993     17595.304688              1.753547   \n",
       "min                  0.000000       265.299988              0.000000   \n",
       "25%                 51.500000     16139.324219              1.600000   \n",
       "50%                 92.599998     35709.046875              2.700000   \n",
       "75%                 99.900002     47349.250000              4.100000   \n",
       "max                100.000000     70518.203125             11.100000   \n",
       "\n",
       "       estimated_45   observed_45  day_of_year_45       hour_45  \\\n",
       "count  28398.000000  28398.000000    28398.000000  28398.000000   \n",
       "mean       0.107296      0.892704      178.688887     11.456828   \n",
       "std        0.309495      0.309495       90.771195      6.724242   \n",
       "min        0.000000      0.000000        1.000000      0.000000   \n",
       "25%        0.000000      1.000000       99.000000      6.000000   \n",
       "50%        0.000000      1.000000      181.000000     11.000000   \n",
       "75%        0.000000      1.000000      255.000000     17.000000   \n",
       "max        1.000000      1.000000      366.000000     23.000000   \n",
       "\n",
       "       pv_measurement  \n",
       "count    28405.000000  \n",
       "mean       756.691448  \n",
       "std       1239.248231  \n",
       "min          0.000000  \n",
       "25%          0.000000  \n",
       "50%         92.180000  \n",
       "75%        969.320000  \n",
       "max       5733.420000  \n",
       "\n",
       "[8 rows x 185 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_0.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = TabularDataset(df1_0)\n",
    "train2 = TabularDataset(df2_0)\n",
    "train3 = TabularDataset(df3_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"ag_144_experimental_4_17A\"\n",
      "Presets specified: ['best_quality']\n",
      "/Users/miksx/.pyenv/versions/3.10.12/envs/TDT4173/lib/python3.10/site-packages/autogluon/core/utils/utils.py:564: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to \"ag_144_experimental_4_17A\"\n",
      "AutoGluon Version:  0.8.3b20231108\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.0.0: Fri Sep 15 14:41:43 PDT 2023; root:xnu-10002.1.13~1/RELEASE_ARM64_T6000\n",
      "Disk Space Avail:   235.08 GB / 494.38 GB (47.5%)\n",
      "Train Data Rows:    28405\n",
      "Train Data Columns: 184\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "/Users/miksx/.pyenv/versions/3.10.12/envs/TDT4173/lib/python3.10/site-packages/autogluon/core/utils/utils.py:564: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (5733.42, 0.0, 756.69145, 1239.24823)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "/Users/miksx/.pyenv/versions/3.10.12/envs/TDT4173/lib/python3.10/site-packages/autogluon/tabular/learner/default_learner.py:215: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5967.0 MB\n",
      "\tTrain Data (Original)  Memory Usage: 22.72 MB (0.4% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 12 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 23): ['snow_drift:idx', 'elevation:m_15', 'snow_density:kgm3_15', 'snow_drift:idx_15', 'estimated_15', 'observed_15', 'day_of_year_15', 'hour_15', 'elevation:m_30', 'snow_density:kgm3_30', 'snow_drift:idx_30', 'snow_melt_10min:mm_30', 'estimated_30', 'observed_30', 'day_of_year_30', 'hour_30', 'elevation:m_45', 'snow_drift:idx_45', 'snow_melt_10min:mm_45', 'estimated_45', 'observed_45', 'day_of_year_45', 'hour_45']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 23 | ['snow_drift:idx', 'elevation:m_15', 'snow_density:kgm3_15', 'snow_drift:idx_15', 'estimated_15', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 161 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 158 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', ['bool']) :   3 | ['elevation:m', 'snow_density:kgm3', 'snow_density:kgm3_45']\n",
      "\t1.0s = Fit runtime\n",
      "\t161 features in original data used to generate 161 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 18.49 MB (0.3% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 39.27s of the 58.92s of remaining time.\n",
      "\t-264.0217\t = Validation score   (-mean_absolute_error)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t1.1s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 36.81s of the 56.46s of remaining time.\n",
      "\t-263.6309\t = Validation score   (-mean_absolute_error)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t1.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 35.65s of the 55.3s of remaining time.\n",
      "2023-11-09 20:56:28,749\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t-191.5628\t = Validation score   (-mean_absolute_error)\n",
      "\t27.17s\t = Training   runtime\n",
      "\t27.14s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 0.36s of the 20.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t-880.9096\t = Validation score   (-mean_absolute_error)\n",
      "\t1.03s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 58.92s of the 17.53s of remaining time.\n",
      "\t-191.56\t = Validation score   (-mean_absolute_error)\n",
      "\t0.21s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 17.31s of the 17.3s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\t-194.5957\t = Validation score   (-mean_absolute_error)\n",
      "\t6.47s\t = Training   runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 9.42s of the 9.41s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\t-192.3989\t = Validation score   (-mean_absolute_error)\n",
      "\t3.94s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 4.37s of the 4.36s of remaining time.\n",
      "\t-192.4054\t = Validation score   (-mean_absolute_error)\n",
      "\t81.26s\t = Training   runtime\n",
      "\t1.36s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 58.92s of the -78.54s of remaining time.\n",
      "\t-189.7884\t = Validation score   (-mean_absolute_error)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 138.79s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"ag_144_experimental_4_17A\")\n"
     ]
    }
   ],
   "source": [
    "predictor1 = TabularPredictor(label=\"pv_measurement\", eval_metric='mean_absolute_error',\n",
    "                              path=PATH+\"A\").fit(\n",
    "    train1,\n",
    "    time_limit=60,\n",
    "    presets='best_quality',\n",
    "    # tuning_data = tuning1,\n",
    "    # use_bag_holdout=True,\n",
    "\n",
    "    # verbosity = 3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = pipin.get_test_data(\"A\")\n",
    "test_data1 = TabularDataset(test1)\n",
    "\n",
    "\n",
    "pred1 = pd.DataFrame(predictor1.predict(test_data1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"ag_144_experimental_4_17B\"\n",
      "Presets specified: ['best_quality']\n",
      "/Users/miksx/.pyenv/versions/3.10.12/envs/TDT4173/lib/python3.10/site-packages/autogluon/core/utils/utils.py:564: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to \"ag_144_experimental_4_17B\"\n",
      "AutoGluon Version:  0.8.3b20231108\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.0.0: Fri Sep 15 14:41:43 PDT 2023; root:xnu-10002.1.13~1/RELEASE_ARM64_T6000\n",
      "Disk Space Avail:   235.02 GB / 494.38 GB (47.5%)\n",
      "Train Data Rows:    19779\n",
      "Train Data Columns: 184\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "/Users/miksx/.pyenv/versions/3.10.12/envs/TDT4173/lib/python3.10/site-packages/autogluon/core/utils/utils.py:564: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (1152.3, 0.0, 140.37621, 233.53347)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "/Users/miksx/.pyenv/versions/3.10.12/envs/TDT4173/lib/python3.10/site-packages/autogluon/tabular/learner/default_learner.py:215: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5968.52 MB\n",
      "\tTrain Data (Original)  Memory Usage: 15.82 MB (0.3% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 12 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 22): ['snow_drift:idx', 'elevation:m_15', 'snow_density:kgm3_15', 'snow_drift:idx_15', 'estimated_15', 'observed_15', 'day_of_year_15', 'hour_15', 'elevation:m_30', 'snow_density:kgm3_30', 'snow_drift:idx_30', 'estimated_30', 'observed_30', 'day_of_year_30', 'hour_30', 'elevation:m_45', 'snow_density:kgm3_45', 'snow_drift:idx_45', 'estimated_45', 'observed_45', 'day_of_year_45', 'hour_45']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 22 | ['snow_drift:idx', 'elevation:m_15', 'snow_density:kgm3_15', 'snow_drift:idx_15', 'estimated_15', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 162 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 160 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', ['bool']) :   2 | ['elevation:m', 'snow_density:kgm3']\n",
      "\t1.0s = Fit runtime\n",
      "\t162 features in original data used to generate 162 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 13.01 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.0s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 39.32s of the 59.0s of remaining time.\n",
      "\t-42.962\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.56s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 38.65s of the 58.33s of remaining time.\n",
      "\t-42.8457\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 37.97s of the 57.65s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\t-29.6502\t = Validation score   (-mean_absolute_error)\n",
      "\t32.0s\t = Training   runtime\n",
      "\t24.17s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 0.99s of the 20.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\t-48.0363\t = Validation score   (-mean_absolute_error)\n",
      "\t1.37s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 59.0s of the 17.87s of remaining time.\n",
      "\t-29.6502\t = Validation score   (-mean_absolute_error)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 17.7s of the 17.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\t-30.7301\t = Validation score   (-mean_absolute_error)\n",
      "\t6.89s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 9.36s of the 9.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\t-30.1524\t = Validation score   (-mean_absolute_error)\n",
      "\t4.12s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 4.13s of the 4.12s of remaining time.\n",
      "\t-29.9053\t = Validation score   (-mean_absolute_error)\n",
      "\t52.33s\t = Training   runtime\n",
      "\t1.01s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 59.0s of the -49.48s of remaining time.\n",
      "\t-29.4444\t = Validation score   (-mean_absolute_error)\n",
      "\t0.25s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 109.74s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"ag_144_experimental_4_17B\")\n"
     ]
    }
   ],
   "source": [
    "predictor2 = TabularPredictor(label=\"pv_measurement\", eval_metric='mean_absolute_error',\n",
    "                              path=PATH+\"B\").fit(\n",
    "    train2,\n",
    "\n",
    "    presets='best_quality', \n",
    "    # hyperparameters='very_large', \n",
    "    time_limit=60,\n",
    "    # tuning_data = tuning2,\n",
    "    # use_bag_holdout=True,\n",
    "    # verbosity = 3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"ag_144_experimental_4_17C\"\n",
      "Presets specified: ['best_quality']\n",
      "/Users/miksx/.pyenv/versions/3.10.12/envs/TDT4173/lib/python3.10/site-packages/autogluon/core/utils/utils.py:564: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to \"ag_144_experimental_4_17C\"\n",
      "AutoGluon Version:  0.8.3b20231108\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.0.0: Fri Sep 15 14:41:43 PDT 2023; root:xnu-10002.1.13~1/RELEASE_ARM64_T6000\n",
      "Disk Space Avail:   235.04 GB / 494.38 GB (47.5%)\n",
      "Train Data Rows:    16819\n",
      "Train Data Columns: 184\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "/Users/miksx/.pyenv/versions/3.10.12/envs/TDT4173/lib/python3.10/site-packages/autogluon/core/utils/utils.py:564: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (999.6, 0.0, 120.42044, 193.67197)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "/Users/miksx/.pyenv/versions/3.10.12/envs/TDT4173/lib/python3.10/site-packages/autogluon/tabular/learner/default_learner.py:215: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5526.64 MB\n",
      "\tTrain Data (Original)  Memory Usage: 13.46 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 12 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 24): ['snow_drift:idx', 'elevation:m_15', 'snow_density:kgm3_15', 'snow_drift:idx_15', 'estimated_15', 'observed_15', 'day_of_year_15', 'hour_15', 'elevation:m_30', 'snow_density:kgm3_30', 'snow_depth:cm_30', 'snow_drift:idx_30', 'estimated_30', 'observed_30', 'day_of_year_30', 'hour_30', 'elevation:m_45', 'snow_density:kgm3_45', 'snow_depth:cm_45', 'snow_drift:idx_45', 'estimated_45', 'observed_45', 'day_of_year_45', 'hour_45']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 24 | ['snow_drift:idx', 'elevation:m_15', 'snow_density:kgm3_15', 'snow_drift:idx_15', 'estimated_15', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 160 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 158 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', ['bool']) :   2 | ['elevation:m', 'snow_density:kgm3']\n",
      "\t1.0s = Fit runtime\n",
      "\t160 features in original data used to generate 160 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.93 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 39.27s of the 58.92s of remaining time.\n",
      "\t-36.7262\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 38.75s of the 58.4s of remaining time.\n",
      "\t-36.6129\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 38.25s of the 57.9s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\t-25.5559\t = Validation score   (-mean_absolute_error)\n",
      "\t32.33s\t = Training   runtime\n",
      "\t22.22s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1.06s of the 20.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\t-36.1178\t = Validation score   (-mean_absolute_error)\n",
      "\t1.44s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 58.92s of the 17.85s of remaining time.\n",
      "\t-25.5559\t = Validation score   (-mean_absolute_error)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 17.68s of the 17.67s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\t-26.3535\t = Validation score   (-mean_absolute_error)\n",
      "\t15.21s\t = Training   runtime\n",
      "\t0.93s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 0.53s of the 0.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\t-107.0086\t = Validation score   (-mean_absolute_error)\n",
      "\t1.17s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 58.92s of the -1.68s of remaining time.\n",
      "\t-25.4822\t = Validation score   (-mean_absolute_error)\n",
      "\t0.21s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 61.91s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"ag_144_experimental_4_17C\")\n"
     ]
    }
   ],
   "source": [
    "predictor3 = TabularPredictor(label=\"pv_measurement\", eval_metric='mean_absolute_error',\n",
    "                              path=PATH+\"C\").fit(\n",
    "    train3,\n",
    "\n",
    "    presets='best_quality', \n",
    "    # hyperparameters='very_large', \n",
    "    time_limit=60,\n",
    "    # tuning_data = tuning3,\n",
    "    # use_bag_holdout=True,\n",
    "    # verbosity = 3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = pipin.get_test_data(\"A\")\n",
    "test2 = pipin.get_test_data(\"B\")\n",
    "test3 = pipin.get_test_data(\"C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data1 = TabularDataset(test1)\n",
    "test_data2 = TabularDataset(test2)\n",
    "test_data3 = TabularDataset(test3)\n",
    "\n",
    "# pred1 = pd.DataFrame(predictor1.predict(test_data1))\n",
    "pred2 = pd.DataFrame(predictor2.predict(test_data2))\n",
    "pred3 = pd.DataFrame(predictor3.predict(test_data3))\n",
    "\n",
    "negatives_pred1 = pred1[pred1[\"pv_measurement\"] < 0]\n",
    "negatives_pred2 = pred2[pred2[\"pv_measurement\"] < 0]\n",
    "negatives_pred3 = pred3[pred3[\"pv_measurement\"] < 0]\n",
    "neg = pd.concat([negatives_pred1, negatives_pred2, negatives_pred3])\n",
    "neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.concat([pred1, pred2, pred3])\n",
    "final_prediction = pipin.post_processing(pred, prediction_column=\"pv_measurement\")\n",
    "final_prediction.to_csv('submissions/gluon_3_exstract_time_3_12.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.969885771833326"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = pipin.compare_mae(final_prediction)\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor.evaluate(df1, silent=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gluon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
