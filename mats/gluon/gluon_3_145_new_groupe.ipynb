{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Tester ny groupering av data.</h3>\n",
    "<p>tester å fjerne 12 like null verider<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matsalexander/.pyenv/versions/3.10.13/envs/gluon/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/matsalexander/Desktop/Forest Gump/mats/gluon\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from pipeline_new_grouping import Pipeline\n",
    "pipin = Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_0 = pipin.get_data(\"A\")\n",
    "df2_0 = pipin.get_data(\"B\")\n",
    "df3_0 = pipin.get_data(\"C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute_humidity_2m:gm3</th>\n",
       "      <th>air_density_2m:kgm3</th>\n",
       "      <th>ceiling_height_agl:m</th>\n",
       "      <th>clear_sky_energy_1h:J</th>\n",
       "      <th>clear_sky_rad:W</th>\n",
       "      <th>cloud_base_agl:m</th>\n",
       "      <th>dew_or_rime:idx</th>\n",
       "      <th>dew_point_2m:K</th>\n",
       "      <th>diffuse_rad:W</th>\n",
       "      <th>diffuse_rad_1h:J</th>\n",
       "      <th>...</th>\n",
       "      <th>wind_speed_10m:ms</th>\n",
       "      <th>wind_speed_u_10m:ms</th>\n",
       "      <th>wind_speed_v_10m:ms</th>\n",
       "      <th>wind_speed_w_1000hPa:ms</th>\n",
       "      <th>estimated</th>\n",
       "      <th>observed</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>hour</th>\n",
       "      <th>pv_measurement</th>\n",
       "      <th>consecutive_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.700</td>\n",
       "      <td>1.23000</td>\n",
       "      <td>1744.900024</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1744.900024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>280.299988</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.700</td>\n",
       "      <td>3.60</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>153.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.700</td>\n",
       "      <td>1.22700</td>\n",
       "      <td>1718.625000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1718.625000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>280.299988</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.550</td>\n",
       "      <td>3.55</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>153.00</td>\n",
       "      <td>22.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.700</td>\n",
       "      <td>1.22250</td>\n",
       "      <td>1680.949951</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1680.949951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>280.274994</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.275</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>153.25</td>\n",
       "      <td>17.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.000</td>\n",
       "      <td>1.21900</td>\n",
       "      <td>1493.300049</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1493.300049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>280.924988</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.950</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>154.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.575</td>\n",
       "      <td>1.21825</td>\n",
       "      <td>1213.449951</td>\n",
       "      <td>1845.375</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1213.449951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>281.924988</td>\n",
       "      <td>1.375</td>\n",
       "      <td>2462.600098</td>\n",
       "      <td>...</td>\n",
       "      <td>2.700</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>154.00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>19.36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   absolute_humidity_2m:gm3  air_density_2m:kgm3  ceiling_height_agl:m  \\\n",
       "0                     7.700              1.23000           1744.900024   \n",
       "1                     7.700              1.22700           1718.625000   \n",
       "2                     7.700              1.22250           1680.949951   \n",
       "3                     8.000              1.21900           1493.300049   \n",
       "4                     8.575              1.21825           1213.449951   \n",
       "\n",
       "   clear_sky_energy_1h:J  clear_sky_rad:W  cloud_base_agl:m  dew_or_rime:idx  \\\n",
       "0                  0.000              0.0       1744.900024              0.0   \n",
       "1                  0.000              0.0       1718.625000              0.0   \n",
       "2                  0.000              0.0       1680.949951              0.0   \n",
       "3                  0.000              0.0       1493.300049              0.0   \n",
       "4               1845.375              3.2       1213.449951              0.0   \n",
       "\n",
       "   dew_point_2m:K  diffuse_rad:W  diffuse_rad_1h:J  ...  wind_speed_10m:ms  \\\n",
       "0      280.299988          0.000          0.000000  ...              3.700   \n",
       "1      280.299988          0.000          0.000000  ...              3.550   \n",
       "2      280.274994          0.000          0.000000  ...              3.275   \n",
       "3      280.924988          0.000          0.000000  ...              2.950   \n",
       "4      281.924988          1.375       2462.600098  ...              2.700   \n",
       "\n",
       "   wind_speed_u_10m:ms  wind_speed_v_10m:ms  wind_speed_w_1000hPa:ms  \\\n",
       "0                 3.60                0.800                      0.0   \n",
       "1                 3.55                0.300                      0.0   \n",
       "2                 3.25                0.450                      0.0   \n",
       "3                 2.85                0.775                      0.0   \n",
       "4                 2.55                0.925                      0.0   \n",
       "\n",
       "   estimated  observed  day_of_year   hour  pv_measurement  consecutive_count  \n",
       "0        0.0       1.0       153.00  22.00            0.00                  4  \n",
       "1        0.0       1.0       153.00  22.25            0.00                  4  \n",
       "2        0.0       1.0       153.25  17.25            0.00                  4  \n",
       "3        0.0       1.0       154.00   0.25            0.00                  4  \n",
       "4        0.0       1.0       154.00   1.25           19.36                  1  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = TabularDataset(df1_0)\n",
    "train2 = TabularDataset(df2_0)\n",
    "train3 = TabularDataset(df3_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231107_160630/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231107_160630/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Thu Jun  8 22:22:20 PDT 2023; root:xnu-8796.121.3~7/RELEASE_ARM64_T6000\n",
      "Disk Space Avail:   563.46 GB / 994.66 GB (56.6%)\n",
      "Train Data Rows:    34042\n",
      "Train Data Columns: 50\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (5733.42, 0.0, 631.39124, 1166.42299)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    12896.16 MB\n",
      "\tTrain Data (Original)  Memory Usage: 7.49 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['snow_drift:idx']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['snow_drift:idx']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 48 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])   :  1 | ['consecutive_count']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 46 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])       :  1 | ['consecutive_count']\n",
      "\t\t('int', ['bool']) :  2 | ['elevation:m', 'snow_density:kgm3']\n",
      "\t0.2s = Fit runtime\n",
      "\t49 features in original data used to generate 49 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 7.15 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.25s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\t-340.4503\t = Validation score   (-mean_absolute_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.92s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\t-340.9441\t = Validation score   (-mean_absolute_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.75s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-165.8766\t = Validation score   (-mean_absolute_error)\n",
      "\t27.02s\t = Training   runtime\n",
      "\t77.41s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-173.5401\t = Validation score   (-mean_absolute_error)\n",
      "\t37.85s\t = Training   runtime\n",
      "\t61.71s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\t-193.4233\t = Validation score   (-mean_absolute_error)\n",
      "\t15.72s\t = Training   runtime\n",
      "\t1.38s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-181.764\t = Validation score   (-mean_absolute_error)\n",
      "\t338.06s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "\t-193.5604\t = Validation score   (-mean_absolute_error)\n",
      "\t9.67s\t = Training   runtime\n",
      "\t1.39s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-195.0701\t = Validation score   (-mean_absolute_error)\n",
      "\t47.54s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-184.8806\t = Validation score   (-mean_absolute_error)\n",
      "\t174.27s\t = Training   runtime\n",
      "\t54.59s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-180.0601\t = Validation score   (-mean_absolute_error)\n",
      "\t131.61s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-168.8846\t = Validation score   (-mean_absolute_error)\n",
      "\t212.71s\t = Training   runtime\n",
      "\t394.71s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-160.935\t = Validation score   (-mean_absolute_error)\n",
      "\t0.48s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-162.0656\t = Validation score   (-mean_absolute_error)\n",
      "\t7.08s\t = Training   runtime\n",
      "\t1.2s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-159.7209\t = Validation score   (-mean_absolute_error)\n",
      "\t4.18s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "\t-158.5022\t = Validation score   (-mean_absolute_error)\n",
      "\t53.33s\t = Training   runtime\n",
      "\t1.08s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-160.0631\t = Validation score   (-mean_absolute_error)\n",
      "\t18.5s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "\t-157.7208\t = Validation score   (-mean_absolute_error)\n",
      "\t11.32s\t = Training   runtime\n",
      "\t1.98s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-157.5744\t = Validation score   (-mean_absolute_error)\n",
      "\t48.37s\t = Training   runtime\n",
      "\t0.78s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-158.5585\t = Validation score   (-mean_absolute_error)\n",
      "\t6.8s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-159.7607\t = Validation score   (-mean_absolute_error)\n",
      "\t60.02s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-160.1091\t = Validation score   (-mean_absolute_error)\n",
      "\t15.15s\t = Training   runtime\n",
      "\t1.18s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-155.304\t = Validation score   (-mean_absolute_error)\n",
      "\t0.55s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1362.39s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231107_160630/\")\n"
     ]
    }
   ],
   "source": [
    "predictor1 = TabularPredictor(label=\"pv_measurement\", eval_metric='mean_absolute_error').fit(\n",
    "    train1,\n",
    "    # time_limit=6000,\n",
    "    # hyperparameters='extrme', \n",
    "    presets='best_quality', \n",
    "    # tuning_data = tuning1,\n",
    "    # use_bag_holdout=True,\n",
    "    # num_bag_folds= 6,\n",
    "    # refit_full = True,\n",
    "    # auto_stack = True,\n",
    "    # num_bag_sets= 10,\n",
    "    # set_best_to_refit_full= True,\n",
    "    # num_stack_levels = 2,\n",
    "    # verbosity = 3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231107_162913/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231107_162913/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Thu Jun  8 22:22:20 PDT 2023; root:xnu-8796.121.3~7/RELEASE_ARM64_T6000\n",
      "Disk Space Avail:   557.83 GB / 994.66 GB (56.1%)\n",
      "Train Data Rows:    25723\n",
      "Train Data Columns: 50\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (1152.3, 0.0, 107.68393, 213.01764)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11431.89 MB\n",
      "\tTrain Data (Original)  Memory Usage: 5.66 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 49 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])   :  1 | ['consecutive_count']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 47 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])       :  1 | ['consecutive_count']\n",
      "\t\t('int', ['bool']) :  2 | ['elevation:m', 'snow_density:kgm3']\n",
      "\t0.2s = Fit runtime\n",
      "\t50 features in original data used to generate 50 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 5.5 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.25s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\t-54.3916\t = Validation score   (-mean_absolute_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t1.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\t-54.3511\t = Validation score   (-mean_absolute_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.9s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-23.4566\t = Validation score   (-mean_absolute_error)\n",
      "\t50.05s\t = Training   runtime\n",
      "\t72.66s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-24.6888\t = Validation score   (-mean_absolute_error)\n",
      "\t94.07s\t = Training   runtime\n",
      "\t105.43s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\t-27.566\t = Validation score   (-mean_absolute_error)\n",
      "\t18.75s\t = Training   runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-25.9021\t = Validation score   (-mean_absolute_error)\n",
      "\t429.93s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "\t-27.55\t = Validation score   (-mean_absolute_error)\n",
      "\t5.95s\t = Training   runtime\n",
      "\t0.74s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-28.3273\t = Validation score   (-mean_absolute_error)\n",
      "\t35.68s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-26.2159\t = Validation score   (-mean_absolute_error)\n",
      "\t161.39s\t = Training   runtime\n",
      "\t67.69s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-26.2214\t = Validation score   (-mean_absolute_error)\n",
      "\t76.21s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-23.99\t = Validation score   (-mean_absolute_error)\n",
      "\t220.99s\t = Training   runtime\n",
      "\t460.03s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-22.8498\t = Validation score   (-mean_absolute_error)\n",
      "\t1.94s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-23.4611\t = Validation score   (-mean_absolute_error)\n",
      "\t28.08s\t = Training   runtime\n",
      "\t1.95s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-22.8831\t = Validation score   (-mean_absolute_error)\n",
      "\t3.9s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "\t-22.6002\t = Validation score   (-mean_absolute_error)\n",
      "\t33.99s\t = Training   runtime\n",
      "\t1.14s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-23.096\t = Validation score   (-mean_absolute_error)\n",
      "\t43.12s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "\t-22.5491\t = Validation score   (-mean_absolute_error)\n",
      "\t7.38s\t = Training   runtime\n",
      "\t1.23s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-22.9703\t = Validation score   (-mean_absolute_error)\n",
      "\t61.43s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-22.7716\t = Validation score   (-mean_absolute_error)\n",
      "\t9.66s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-23.1974\t = Validation score   (-mean_absolute_error)\n",
      "\t56.82s\t = Training   runtime\n",
      "\t0.44s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-22.9375\t = Validation score   (-mean_absolute_error)\n",
      "\t9.82s\t = Training   runtime\n",
      "\t0.81s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-22.2677\t = Validation score   (-mean_absolute_error)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1547.61s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231107_162913/\")\n"
     ]
    }
   ],
   "source": [
    "predictor2 = TabularPredictor(label=\"pv_measurement\", eval_metric='mean_absolute_error').fit(\n",
    "    train2,\n",
    "\n",
    "    presets='best_quality', \n",
    "    # hyperparameters='very_large', \n",
    "    # time_limit=6000,\n",
    "    # tuning_data = tuning2,\n",
    "    # use_bag_holdout=True,\n",
    "    # num_bag_folds= 6,\n",
    "    # refit_full = True,\n",
    "    # auto_stack = True,\n",
    "    # num_bag_sets= 10,\n",
    "    # set_best_to_refit_full= True,\n",
    "    # num_stack_levels = 2,\n",
    "    # verbosity = 3\n",
    "    )\n",
    "\n",
    "# tuning_data\n",
    "# num bag holdout 6\n",
    "# bag_holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231107_165501/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231107_165501/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Thu Jun  8 22:22:20 PDT 2023; root:xnu-8796.121.3~7/RELEASE_ARM64_T6000\n",
      "Disk Space Avail:   550.08 GB / 994.66 GB (55.3%)\n",
      "Train Data Rows:    20949\n",
      "Train Data Columns: 50\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (999.6, 0.0, 96.47117, 180.05602)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11347.76 MB\n",
      "\tTrain Data (Original)  Memory Usage: 4.61 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['snow_drift:idx']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['snow_drift:idx']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 48 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])   :  1 | ['consecutive_count']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 46 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])       :  1 | ['consecutive_count']\n",
      "\t\t('int', ['bool']) :  2 | ['elevation:m', 'snow_density:kgm3']\n",
      "\t0.3s = Fit runtime\n",
      "\t49 features in original data used to generate 49 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 4.4 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.38s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\t-42.8652\t = Validation score   (-mean_absolute_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\t-42.9713\t = Validation score   (-mean_absolute_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-20.7167\t = Validation score   (-mean_absolute_error)\n",
      "\t36.35s\t = Training   runtime\n",
      "\t45.89s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-21.7899\t = Validation score   (-mean_absolute_error)\n",
      "\t58.58s\t = Training   runtime\n",
      "\t43.18s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\t-24.01\t = Validation score   (-mean_absolute_error)\n",
      "\t11.13s\t = Training   runtime\n",
      "\t0.5s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-22.3442\t = Validation score   (-mean_absolute_error)\n",
      "\t468.87s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "\t-23.8412\t = Validation score   (-mean_absolute_error)\n",
      "\t3.83s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-23.9995\t = Validation score   (-mean_absolute_error)\n",
      "\t28.54s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-22.6595\t = Validation score   (-mean_absolute_error)\n",
      "\t161.25s\t = Training   runtime\n",
      "\t41.96s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-22.47\t = Validation score   (-mean_absolute_error)\n",
      "\t55.79s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-21.1888\t = Validation score   (-mean_absolute_error)\n",
      "\t234.84s\t = Training   runtime\n",
      "\t172.78s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-20.1288\t = Validation score   (-mean_absolute_error)\n",
      "\t0.25s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-20.9237\t = Validation score   (-mean_absolute_error)\n",
      "\t11.02s\t = Training   runtime\n",
      "\t0.9s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-20.5347\t = Validation score   (-mean_absolute_error)\n",
      "\t5.36s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "\t-20.2153\t = Validation score   (-mean_absolute_error)\n",
      "\t27.47s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-20.8197\t = Validation score   (-mean_absolute_error)\n",
      "\t14.91s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "\t-20.0988\t = Validation score   (-mean_absolute_error)\n",
      "\t6.12s\t = Training   runtime\n",
      "\t0.66s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-20.493\t = Validation score   (-mean_absolute_error)\n",
      "\t27.75s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-20.537\t = Validation score   (-mean_absolute_error)\n",
      "\t8.13s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-20.5066\t = Validation score   (-mean_absolute_error)\n",
      "\t37.39s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-20.7313\t = Validation score   (-mean_absolute_error)\n",
      "\t21.82s\t = Training   runtime\n",
      "\t1.09s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-19.9113\t = Validation score   (-mean_absolute_error)\n",
      "\t0.25s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1332.85s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231107_165501/\")\n"
     ]
    }
   ],
   "source": [
    "predictor3 = TabularPredictor(label=\"pv_measurement\", eval_metric='mean_absolute_error' ).fit(\n",
    "    train3,\n",
    "\n",
    "    presets='best_quality', \n",
    "    # hyperparameters='very_large', \n",
    "    # time_limit=6000,\n",
    "    # tuning_data = tuning3,\n",
    "    # use_bag_holdout=True,\n",
    "    # num_bag_folds= 6,\n",
    "    # refit_full = True,\n",
    "    # auto_stack = True,\n",
    "    # num_bag_sets= 10,\n",
    "    # set_best_to_refit_full= True,\n",
    "    # num_stack_levels = 2,\n",
    "    # verbosity = 3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = pipin.get_test_data(\"A\")\n",
    "test2 = pipin.get_test_data(\"B\")\n",
    "test3 = pipin.get_test_data(\"C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"1 required columns are missing from the provided dataset to transform using AutoMLPipelineFeatureGenerator. 1 missing columns: ['consecutive_count'] | 49 available columns: ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', 'cloud_base_agl:m', 'dew_or_rime:idx', 'dew_point_2m:K', 'diffuse_rad:W', 'diffuse_rad_1h:J', 'direct_rad:W', 'direct_rad_1h:J', 'effective_cloud_cover:p', 'elevation:m', 'fresh_snow_12h:cm', 'fresh_snow_1h:cm', 'fresh_snow_24h:cm', 'fresh_snow_3h:cm', 'fresh_snow_6h:cm', 'is_day:idx', 'is_in_shadow:idx', 'msl_pressure:hPa', 'precip_5min:mm', 'precip_type_5min:idx', 'pressure_100m:hPa', 'pressure_50m:hPa', 'prob_rime:p', 'rain_water:kgm2', 'relative_humidity_1000hPa:p', 'sfc_pressure:hPa', 'snow_density:kgm3', 'snow_depth:cm', 'snow_drift:idx', 'snow_melt_10min:mm', 'snow_water:kgm2', 'sun_azimuth:d', 'sun_elevation:d', 'super_cooled_liquid_water:kgm2', 't_1000hPa:K', 'total_cloud_cover:p', 'visibility:m', 'wind_speed_10m:ms', 'wind_speed_u_10m:ms', 'wind_speed_v_10m:ms', 'wind_speed_w_1000hPa:ms', 'estimated', 'observed', 'day_of_year', 'hour']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/gluon/lib/python3.10/site-packages/autogluon/features/generators/abstract.py:338\u001b[0m, in \u001b[0;36mAbstractFeatureGenerator.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlist\u001b[39m(X\u001b[39m.\u001b[39mcolumns) \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures_in:\n\u001b[1;32m    336\u001b[0m         \u001b[39m# It comes at a cost when making a copy of the DataFrame,\u001b[39;00m\n\u001b[1;32m    337\u001b[0m         \u001b[39m# therefore, try avoid copying by checking the expected features first.\u001b[39;00m\n\u001b[0;32m--> 338\u001b[0m         X \u001b[39m=\u001b[39m X[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures_in]\n\u001b[1;32m    339\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/gluon/lib/python3.10/site-packages/pandas/core/frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3812\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3813\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3815\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/gluon/lib/python3.10/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/gluon/lib/python3.10/site-packages/pandas/core/indexes/base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6132\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m-> 6133\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['consecutive_count'] not in index\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/matsalexander/Desktop/Forest Gump/mats/gluon/gluon_3_145_new_groupe.ipynb Cell 12\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matsalexander/Desktop/Forest%20Gump/mats/gluon/gluon_3_145_new_groupe.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m test_data2 \u001b[39m=\u001b[39m TabularDataset(test2)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matsalexander/Desktop/Forest%20Gump/mats/gluon/gluon_3_145_new_groupe.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m test_data3 \u001b[39m=\u001b[39m TabularDataset(test3)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/matsalexander/Desktop/Forest%20Gump/mats/gluon/gluon_3_145_new_groupe.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m pred1 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(predictor1\u001b[39m.\u001b[39;49mpredict(test_data1))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matsalexander/Desktop/Forest%20Gump/mats/gluon/gluon_3_145_new_groupe.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m pred2 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(predictor2\u001b[39m.\u001b[39mpredict(test_data2))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matsalexander/Desktop/Forest%20Gump/mats/gluon/gluon_3_145_new_groupe.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m pred3 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(predictor3\u001b[39m.\u001b[39mpredict(test_data3))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/gluon/lib/python3.10/site-packages/autogluon/tabular/predictor/predictor.py:1579\u001b[0m, in \u001b[0;36mTabularPredictor.predict\u001b[0;34m(self, data, model, as_pandas, transform_features, decision_threshold)\u001b[0m\n\u001b[1;32m   1577\u001b[0m \u001b[39mif\u001b[39;00m decision_threshold \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1578\u001b[0m     decision_threshold \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecision_threshold\n\u001b[0;32m-> 1579\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_learner\u001b[39m.\u001b[39;49mpredict(X\u001b[39m=\u001b[39;49mdata, model\u001b[39m=\u001b[39;49mmodel, as_pandas\u001b[39m=\u001b[39;49mas_pandas, transform_features\u001b[39m=\u001b[39;49mtransform_features, decision_threshold\u001b[39m=\u001b[39;49mdecision_threshold)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/gluon/lib/python3.10/site-packages/autogluon/tabular/learner/abstract_learner.py:208\u001b[0m, in \u001b[0;36mAbstractTabularLearner.predict\u001b[0;34m(self, X, model, as_pandas, inverse_transform, transform_features, decision_threshold)\u001b[0m\n\u001b[1;32m    206\u001b[0m     decision_threshold \u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m\n\u001b[1;32m    207\u001b[0m X_index \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(X\u001b[39m.\u001b[39mindex) \u001b[39mif\u001b[39;00m as_pandas \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m y_pred_proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(\n\u001b[1;32m    209\u001b[0m     X\u001b[39m=\u001b[39;49mX, model\u001b[39m=\u001b[39;49mmodel, as_pandas\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, as_multiclass\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, inverse_transform\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, transform_features\u001b[39m=\u001b[39;49mtransform_features\n\u001b[1;32m    210\u001b[0m )\n\u001b[1;32m    211\u001b[0m problem_type \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel_cleaner\u001b[39m.\u001b[39mproblem_type_transform \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproblem_type\n\u001b[1;32m    212\u001b[0m y_pred \u001b[39m=\u001b[39m get_pred_from_proba(y_pred_proba\u001b[39m=\u001b[39my_pred_proba, problem_type\u001b[39m=\u001b[39mproblem_type, decision_threshold\u001b[39m=\u001b[39mdecision_threshold)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/gluon/lib/python3.10/site-packages/autogluon/tabular/learner/abstract_learner.py:188\u001b[0m, in \u001b[0;36mAbstractTabularLearner.predict_proba\u001b[0;34m(self, X, model, as_pandas, as_multiclass, inverse_transform, transform_features)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[39mif\u001b[39;00m transform_features:\n\u001b[0;32m--> 188\u001b[0m         X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform_features(X)\n\u001b[1;32m    189\u001b[0m     y_pred_proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_trainer()\u001b[39m.\u001b[39mpredict_proba(X, model\u001b[39m=\u001b[39mmodel)\n\u001b[1;32m    190\u001b[0m y_pred_proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_post_process_predict_proba(\n\u001b[1;32m    191\u001b[0m     y_pred_proba\u001b[39m=\u001b[39my_pred_proba, as_pandas\u001b[39m=\u001b[39mas_pandas, index\u001b[39m=\u001b[39mX_index, as_multiclass\u001b[39m=\u001b[39mas_multiclass, inverse_transform\u001b[39m=\u001b[39minverse_transform\n\u001b[1;32m    192\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/gluon/lib/python3.10/site-packages/autogluon/tabular/learner/abstract_learner.py:462\u001b[0m, in \u001b[0;36mAbstractTabularLearner.transform_features\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform_features\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    461\u001b[0m     \u001b[39mfor\u001b[39;00m feature_generator \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_generators:\n\u001b[0;32m--> 462\u001b[0m         X \u001b[39m=\u001b[39m feature_generator\u001b[39m.\u001b[39;49mtransform(X)\n\u001b[1;32m    463\u001b[0m     \u001b[39mreturn\u001b[39;00m X\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/gluon/lib/python3.10/site-packages/autogluon/features/generators/abstract.py:344\u001b[0m, in \u001b[0;36mAbstractFeatureGenerator.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[39mif\u001b[39;00m col \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m X\u001b[39m.\u001b[39mcolumns:\n\u001b[1;32m    343\u001b[0m             missing_cols\u001b[39m.\u001b[39mappend(col)\n\u001b[0;32m--> 344\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\n\u001b[1;32m    345\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(missing_cols)\u001b[39m}\u001b[39;00m\u001b[39m required columns are missing from the provided dataset to transform using \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    346\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(missing_cols)\u001b[39m}\u001b[39;00m\u001b[39m missing columns: \u001b[39m\u001b[39m{\u001b[39;00mmissing_cols\u001b[39m}\u001b[39;00m\u001b[39m | \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    347\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mlist\u001b[39m(X\u001b[39m.\u001b[39mcolumns))\u001b[39m}\u001b[39;00m\u001b[39m available columns: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(X\u001b[39m.\u001b[39mcolumns)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    348\u001b[0m     )\n\u001b[1;32m    349\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pre_astype_generator:\n\u001b[1;32m    350\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pre_astype_generator\u001b[39m.\u001b[39mtransform(X)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"1 required columns are missing from the provided dataset to transform using AutoMLPipelineFeatureGenerator. 1 missing columns: ['consecutive_count'] | 49 available columns: ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', 'cloud_base_agl:m', 'dew_or_rime:idx', 'dew_point_2m:K', 'diffuse_rad:W', 'diffuse_rad_1h:J', 'direct_rad:W', 'direct_rad_1h:J', 'effective_cloud_cover:p', 'elevation:m', 'fresh_snow_12h:cm', 'fresh_snow_1h:cm', 'fresh_snow_24h:cm', 'fresh_snow_3h:cm', 'fresh_snow_6h:cm', 'is_day:idx', 'is_in_shadow:idx', 'msl_pressure:hPa', 'precip_5min:mm', 'precip_type_5min:idx', 'pressure_100m:hPa', 'pressure_50m:hPa', 'prob_rime:p', 'rain_water:kgm2', 'relative_humidity_1000hPa:p', 'sfc_pressure:hPa', 'snow_density:kgm3', 'snow_depth:cm', 'snow_drift:idx', 'snow_melt_10min:mm', 'snow_water:kgm2', 'sun_azimuth:d', 'sun_elevation:d', 'super_cooled_liquid_water:kgm2', 't_1000hPa:K', 'total_cloud_cover:p', 'visibility:m', 'wind_speed_10m:ms', 'wind_speed_u_10m:ms', 'wind_speed_v_10m:ms', 'wind_speed_w_1000hPa:ms', 'estimated', 'observed', 'day_of_year', 'hour']\""
     ]
    }
   ],
   "source": [
    "test_data1 = TabularDataset(test1)\n",
    "test_data2 = TabularDataset(test2)\n",
    "test_data3 = TabularDataset(test3)\n",
    "\n",
    "pred1 = pd.DataFrame(predictor1.predict(test_data1))\n",
    "pred2 = pd.DataFrame(predictor2.predict(test_data2))\n",
    "pred3 = pd.DataFrame(predictor3.predict(test_data3))\n",
    "\n",
    "negatives_pred1 = pred1[pred1[\"pv_measurement\"] < 0]\n",
    "negatives_pred2 = pred2[pred2[\"pv_measurement\"] < 0]\n",
    "negatives_pred3 = pred3[pred3[\"pv_measurement\"] < 0]\n",
    "neg = pd.concat([negatives_pred1, negatives_pred2, negatives_pred3])\n",
    "neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_unique_filename\n",
    "pred = pd.concat([pred1, pred2, pred3])\n",
    "final_prediction = pipin.post_processing(pred, prediction_column=\"pv_measurement\")\n",
    "final_prediction.to_csv(get_unique_filename('gluon_3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.67033104400012"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = pipin.compare_mae(final_prediction)\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor.evaluate(df1, silent=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gluon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
