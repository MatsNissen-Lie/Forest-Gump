{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matsalexander/.pyenv/versions/3.10.13/envs/gluon/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/matsalexander/Desktop/Forest Gump/mats/gluon\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from pipeline import Pipin\n",
    "pipin = Pipin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_0 = pipin.get_data(\"A\")\n",
    "df2_0 = pipin.get_data(\"B\")\n",
    "df3_0 = pipin.get_data(\"C\")\n",
    "\n",
    "df1, tuning1 = pipin.split_train_tune(df1_0)\n",
    "df2, tuning2 = pipin.split_train_tune(df2_0)\n",
    "df3, tuning3 = pipin.split_train_tune(df3_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1, tuning1 = TabularDataset(df1), TabularDataset(tuning1)\n",
    "train2, tuning2 = TabularDataset(df2), TabularDataset(tuning2)\n",
    "train3, tuning3 = TabularDataset(df3), TabularDataset(tuning3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231104_143430/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 6000s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231104_143430/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Thu Jun  8 22:22:20 PDT 2023; root:xnu-8796.121.3~7/RELEASE_ARM64_T6000\n",
      "Disk Space Avail:   790.09 GB / 994.66 GB (79.4%)\n",
      "Train Data Rows:    20323\n",
      "Train Data Columns: 48\n",
      "Tuning Data Rows:    20331\n",
      "Tuning Data Columns: 48\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (5733.42, 0.0, 1030.20888, 1345.64995)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16291.87 MB\n",
      "\tTrain Data (Original)  Memory Usage: 9.11 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['snow_drift:idx']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['snow_drift:idx']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('datetime', []) :  2 | ['time', 'date_calc']\n",
      "\t\t('float', [])    : 45 | ['snow_melt_10min:mm', 'diffuse_rad_1h:J', 'visibility:m', 'rain_water:kgm2', 'super_cooled_liquid_water:kgm2', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 43 | ['snow_melt_10min:mm', 'diffuse_rad_1h:J', 'visibility:m', 'rain_water:kgm2', 'super_cooled_liquid_water:kgm2', ...]\n",
      "\t\t('int', ['bool'])            :  2 | ['elevation:m', 'snow_density:kgm3']\n",
      "\t\t('int', ['datetime_as_int']) : 10 | ['time', 'time.year', 'time.month', 'time.day', 'time.dayofweek', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t47 features in original data used to generate 55 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 11.14 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.26s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "use_bag_holdout=True, will use tuning_data as holdout (will not be used for early stopping).\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 3998.82s of the 5999.73s of remaining time.\n",
      "\t-310.2512\t = Validation score   (-mean_absolute_error)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 3997.0s of the 5997.91s of remaining time.\n",
      "\t-71.8226\t = Validation score   (-mean_absolute_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3996.29s of the 5997.2s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-74.5201\t = Validation score   (-mean_absolute_error)\n",
      "\t183.88s\t = Training   runtime\n",
      "\t37.69s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 3737.44s of the 5738.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-58.8148\t = Validation score   (-mean_absolute_error)\n",
      "\t134.67s\t = Training   runtime\n",
      "\t578.49s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 3427.7s of the 5428.61s of remaining time.\n",
      "\t-127.9163\t = Validation score   (-mean_absolute_error)\n",
      "\t139.29s\t = Training   runtime\n",
      "\t0.65s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 3287.25s of the 5288.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-96.9862\t = Validation score   (-mean_absolute_error)\n",
      "\t1124.58s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 2160.62s of the 4161.53s of remaining time.\n",
      "\t-123.0782\t = Validation score   (-mean_absolute_error)\n",
      "\t3.1s\t = Training   runtime\n",
      "\t0.7s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 2156.25s of the 4157.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-232.5661\t = Validation score   (-mean_absolute_error)\n",
      "\t11.73s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 2140.98s of the 4141.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-62.1464\t = Validation score   (-mean_absolute_error)\n",
      "\t80.27s\t = Training   runtime\n",
      "\t39.21s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 2032.1s of the 4033.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=\"pv_measurement\", eval_metric='mean_absolute_error').fit(\n",
    "    train1,\n",
    "    time_limit=6000,\n",
    "\n",
    "    presets='best_quality', \n",
    "    # hyperparameters='very_large', \n",
    "    tuning_data = tuning1,\n",
    "    use_bag_holdout=True,\n",
    "    # num_bag_folds= 6,\n",
    "    # refit_full = True,\n",
    "    # auto_stack = True,\n",
    "    # num_bag_sets= 10,\n",
    "    # set_best_to_refit_full= True,\n",
    "    # num_stack_levels = 2,\n",
    "    # verbosity = 3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231103_160515/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231103_160515/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Thu Jun  8 22:22:20 PDT 2023; root:xnu-8796.121.3~7/RELEASE_ARM64_T6000\n",
      "Disk Space Avail:   790.26 GB / 994.66 GB (79.4%)\n",
      "Train Data Rows:    14757\n",
      "Train Data Columns: 51\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (1152.3, -0.0, 188.17893, 253.18265)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    15623.51 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.36 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['elevation:m', 'snow_drift:idx']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('datetime', []) :  2 | ['time', 'date_calc']\n",
      "\t\t('float', [])    : 43 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])      :  4 | ['is_estimated:idx', 'day_of_year', 'hour', 'month']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 39 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])                  :  3 | ['day_of_year', 'hour', 'month']\n",
      "\t\t('int', ['bool'])            :  5 | ['is_day:idx', 'is_in_shadow:idx', 'snow_density:kgm3', 'wind_speed_w_1000hPa:ms', 'is_estimated:idx']\n",
      "\t\t('int', ['datetime_as_int']) :  9 | ['time', 'time.year', 'time.day', 'time.dayofweek', 'date_calc', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t49 features in original data used to generate 56 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 3.79 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.22s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 13281, Val Rows: 1476\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-104.9241\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-79.1337\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 71.5104\n",
      "[2000]\tvalid_set's rmse: 69.2496\n",
      "[3000]\tvalid_set's rmse: 68.5869\n",
      "[4000]\tvalid_set's rmse: 68.0754\n",
      "[5000]\tvalid_set's rmse: 67.7746\n",
      "[6000]\tvalid_set's rmse: 67.6428\n",
      "[7000]\tvalid_set's rmse: 67.5378\n",
      "[8000]\tvalid_set's rmse: 67.4511\n",
      "[9000]\tvalid_set's rmse: 67.4164\n",
      "[10000]\tvalid_set's rmse: 67.2909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-67.2872\t = Validation score   (-root_mean_squared_error)\n",
      "\t68.31s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 74.4439\n",
      "[2000]\tvalid_set's rmse: 73.3697\n",
      "[3000]\tvalid_set's rmse: 73.0204\n",
      "[4000]\tvalid_set's rmse: 72.8835\n",
      "[5000]\tvalid_set's rmse: 72.8263\n",
      "[6000]\tvalid_set's rmse: 72.7736\n",
      "[7000]\tvalid_set's rmse: 72.7459\n",
      "[8000]\tvalid_set's rmse: 72.7274\n",
      "[9000]\tvalid_set's rmse: 72.7229\n",
      "[10000]\tvalid_set's rmse: 72.7196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-72.7195\t = Validation score   (-root_mean_squared_error)\n",
      "\t62.79s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-82.0518\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.18s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-71.3683\t = Validation score   (-root_mean_squared_error)\n",
      "\t69.83s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-79.6772\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.39s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-76.661\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.36s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-75.6402\t = Validation score   (-root_mean_squared_error)\n",
      "\t25.42s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-78.4854\t = Validation score   (-root_mean_squared_error)\n",
      "\t19.66s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 72.8009\n",
      "[2000]\tvalid_set's rmse: 72.4846\n",
      "[3000]\tvalid_set's rmse: 72.4524\n",
      "[4000]\tvalid_set's rmse: 72.4444\n",
      "[5000]\tvalid_set's rmse: 72.4428\n",
      "[6000]\tvalid_set's rmse: 72.4424\n",
      "[7000]\tvalid_set's rmse: 72.4423\n",
      "[8000]\tvalid_set's rmse: 72.4422\n",
      "[9000]\tvalid_set's rmse: 72.4422\n",
      "[10000]\tvalid_set's rmse: 72.4422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-72.4422\t = Validation score   (-root_mean_squared_error)\n",
      "\t260.77s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-63.1836\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 532.86s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231103_160515/\")\n"
     ]
    }
   ],
   "source": [
    "predictor2 = TabularPredictor(label=\"pv_measurement\", eval_metric='mean_absolute_error').fit(\n",
    "    train2,\n",
    "    time_limit=6000,\n",
    "\n",
    "    presets='best_quality', \n",
    "    # hyperparameters='very_large', \n",
    "    tuning_data = tuning2,\n",
    "    use_bag_holdout=True,\n",
    "    # num_bag_folds= 6,\n",
    "    # refit_full = True,\n",
    "    # auto_stack = True,\n",
    "    # num_bag_sets= 10,\n",
    "    # set_best_to_refit_full= True,\n",
    "    # num_stack_levels = 2,\n",
    "    # verbosity = 3\n",
    "    )\n",
    "\n",
    "# tuning_data\n",
    "# num bag holdout 6\n",
    "# bag_holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231104_143141-001/\"\n",
      "Presets specified: ['best_quality']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Valid hyperparameter config names are: ['default', 'light', 'very_light', 'toy', 'multimodal', 'interpretable', 'zeroshot_hpo', 'zeroshot_hpo_hybrid', 'default_FTT', 'extreme'], but 'very_large' was given instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/matsalexander/Desktop/Forest Gump/mats/gluon/gluon.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/matsalexander/Desktop/Forest%20Gump/mats/gluon/gluon.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m predictor3 \u001b[39m=\u001b[39m TabularPredictor(label\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpv_measurement\u001b[39;49m\u001b[39m\"\u001b[39;49m, eval_metric\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmean_absolute_error\u001b[39;49m\u001b[39m'\u001b[39;49m )\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matsalexander/Desktop/Forest%20Gump/mats/gluon/gluon.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     train3,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matsalexander/Desktop/Forest%20Gump/mats/gluon/gluon.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     time_limit\u001b[39m=\u001b[39;49m\u001b[39m6000\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matsalexander/Desktop/Forest%20Gump/mats/gluon/gluon.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matsalexander/Desktop/Forest%20Gump/mats/gluon/gluon.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     presets\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mbest_quality\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matsalexander/Desktop/Forest%20Gump/mats/gluon/gluon.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     hyperparameters\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mvery_large\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matsalexander/Desktop/Forest%20Gump/mats/gluon/gluon.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     tuning_data \u001b[39m=\u001b[39;49m tuning3,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matsalexander/Desktop/Forest%20Gump/mats/gluon/gluon.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     use_bag_holdout\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matsalexander/Desktop/Forest%20Gump/mats/gluon/gluon.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m# num_bag_folds= 6,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matsalexander/Desktop/Forest%20Gump/mats/gluon/gluon.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# refit_full = True,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matsalexander/Desktop/Forest%20Gump/mats/gluon/gluon.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m# auto_stack = True,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matsalexander/Desktop/Forest%20Gump/mats/gluon/gluon.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m# num_bag_sets= 10,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matsalexander/Desktop/Forest%20Gump/mats/gluon/gluon.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m# set_best_to_refit_full= True,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matsalexander/Desktop/Forest%20Gump/mats/gluon/gluon.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m# num_stack_levels = 2,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matsalexander/Desktop/Forest%20Gump/mats/gluon/gluon.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39m# verbosity = 3\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matsalexander/Desktop/Forest%20Gump/mats/gluon/gluon.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/gluon/lib/python3.10/site-packages/autogluon/core/utils/decorators.py:31\u001b[0m, in \u001b[0;36munpack.<locals>._unpack_inner.<locals>._call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     30\u001b[0m     gargs, gkwargs \u001b[39m=\u001b[39m g(\u001b[39m*\u001b[39mother_args, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 31\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49mgargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mgkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/gluon/lib/python3.10/site-packages/autogluon/tabular/predictor/predictor.py:908\u001b[0m, in \u001b[0;36mTabularPredictor.fit\u001b[0;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, calibrate_decision_threshold, num_cpus, num_gpus, **kwargs)\u001b[0m\n\u001b[1;32m    906\u001b[0m     hyperparameters \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    907\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(hyperparameters, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 908\u001b[0m     hyperparameters \u001b[39m=\u001b[39m get_hyperparameter_config(hyperparameters)\n\u001b[1;32m    910\u001b[0m \u001b[39m# TODO: Hyperparam could have non-serializble objects. Save as pkl and loaded on demand\u001b[39;00m\n\u001b[1;32m    911\u001b[0m \u001b[39m# in case the hyperprams are large in memory\u001b[39;00m\n\u001b[1;32m    912\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_hyperparameters_ \u001b[39m=\u001b[39m hyperparameters\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/gluon/lib/python3.10/site-packages/autogluon/tabular/configs/hyperparameter_configs.py:368\u001b[0m, in \u001b[0;36mget_hyperparameter_config\u001b[0;34m(config_name)\u001b[0m\n\u001b[1;32m    366\u001b[0m config_options \u001b[39m=\u001b[39m get_hyperparameter_config_options()\n\u001b[1;32m    367\u001b[0m \u001b[39mif\u001b[39;00m config_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m config_options:\n\u001b[0;32m--> 368\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mValid hyperparameter config names are: \u001b[39m\u001b[39m{\u001b[39;00mconfig_options\u001b[39m}\u001b[39;00m\u001b[39m, but \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mconfig_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m was given instead.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    369\u001b[0m \u001b[39mreturn\u001b[39;00m copy\u001b[39m.\u001b[39mdeepcopy(hyperparameter_config_dict[config_name])\n",
      "\u001b[0;31mValueError\u001b[0m: Valid hyperparameter config names are: ['default', 'light', 'very_light', 'toy', 'multimodal', 'interpretable', 'zeroshot_hpo', 'zeroshot_hpo_hybrid', 'default_FTT', 'extreme'], but 'very_large' was given instead."
     ]
    }
   ],
   "source": [
    "predictor3 = TabularPredictor(label=\"pv_measurement\", eval_metric='mean_absolute_error' ).fit(\n",
    "    train3,\n",
    "    time_limit=6000,\n",
    "\n",
    "    presets='best_quality', \n",
    "    # hyperparameters='very_large', \n",
    "    tuning_data = tuning3,\n",
    "    use_bag_holdout=True,\n",
    "    # num_bag_folds= 6,\n",
    "    # refit_full = True,\n",
    "    # auto_stack = True,\n",
    "    # num_bag_sets= 10,\n",
    "    # set_best_to_refit_full= True,\n",
    "    # num_stack_levels = 2,\n",
    "    # verbosity = 3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = pipin.get_test_data(\"A\")\n",
    "test2 = pipin.get_test_data(\"B\")\n",
    "test3 = pipin.get_test_data(\"C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/matsalexander/Desktop/Forest Gump/mats/gluon/gluon.ipynb Cell 10\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matsalexander/Desktop/Forest%20Gump/mats/gluon/gluon.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m test_data2 \u001b[39m=\u001b[39m TabularDataset(test2)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matsalexander/Desktop/Forest%20Gump/mats/gluon/gluon.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m test_data3 \u001b[39m=\u001b[39m TabularDataset(test3)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/matsalexander/Desktop/Forest%20Gump/mats/gluon/gluon.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m pred1 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(predictor\u001b[39m.\u001b[39mpredict(test_data1))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matsalexander/Desktop/Forest%20Gump/mats/gluon/gluon.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m pred2 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(predictor2\u001b[39m.\u001b[39mpredict(test_data2))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matsalexander/Desktop/Forest%20Gump/mats/gluon/gluon.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m pred3 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(predictor3\u001b[39m.\u001b[39mpredict(test_data3))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictor' is not defined"
     ]
    }
   ],
   "source": [
    "test_data1 = TabularDataset(test1)\n",
    "test_data2 = TabularDataset(test2)\n",
    "test_data3 = TabularDataset(test3)\n",
    "\n",
    "pred1 = pd.DataFrame(predictor.predict(test_data1))\n",
    "pred2 = pd.DataFrame(predictor2.predict(test_data2))\n",
    "pred3 = pd.DataFrame(predictor3.predict(test_data3))\n",
    "\n",
    "negatives_pred1 = pred1[pred1[\"pv_measurement\"] < 0]\n",
    "negatives_pred2 = pred2[pred2[\"pv_measurement\"] < 0]\n",
    "negatives_pred3 = pred3[pred3[\"pv_measurement\"] < 0]\n",
    "neg = pd.concat([negatives_pred1, negatives_pred2, negatives_pred3])\n",
    "neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_unique_filename\n",
    "pred = pd.concat([pred1, pred2, pred3])\n",
    "final_prediction = pipin.post_processing(pred, prediction_column=\"pv_measurement\")\n",
    "final_prediction.to_csv(get_unique_filename('gluon'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179.18834438349012"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = pipin.compare_mae(final_prediction)\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': -141.59062992788995,\n",
       " 'mean_squared_error': -20047.906483376682,\n",
       " 'mean_absolute_error': -59.25292336122937,\n",
       " 'r2': 0.988824833399717,\n",
       " 'pearsonr': 0.9945011969990492,\n",
       " 'median_absolute_error': -21.811315155029263}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictor.evaluate(df1, silent=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gluon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
