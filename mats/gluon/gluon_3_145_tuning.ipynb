{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> tester ny consecutives function.</h3>\n",
    "<p>ny ga 146.16. hva git gammel?r<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matsalexander/.pyenv/versions/3.10.13/envs/gluon/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/matsalexander/Desktop/Forest Gump/mats/gluon\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from pipeline import Pipeline\n",
    "pipin = Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_0 = pipin.get_data(\"A\")\n",
    "df2_0 = pipin.get_data(\"B\")\n",
    "df3_0 = pipin.get_data(\"C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_consecutive_measurments\n",
    "# 6/24\n",
    "# split_train_summer_2021 test this\n",
    "df1_0 = pipin.remove_consecutive_measurments(df1_0, 4, 24)\n",
    "df2_0 = pipin.remove_consecutive_measurments(df2_0, 4, 24)\n",
    "df3_0 = pipin.remove_consecutive_measurments(df3_0, 4, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning\n",
    "train1, tune1 = pipin.split_train_tune(df1_0 )\n",
    "train2, tune2 = pipin.split_train_tune(df2_0 )\n",
    "train3, tune3 = pipin.split_train_tune(df3_0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute_humidity_2m:gm3</th>\n",
       "      <th>air_density_2m:kgm3</th>\n",
       "      <th>ceiling_height_agl:m</th>\n",
       "      <th>clear_sky_energy_1h:J</th>\n",
       "      <th>clear_sky_rad:W</th>\n",
       "      <th>cloud_base_agl:m</th>\n",
       "      <th>dew_or_rime:idx</th>\n",
       "      <th>dew_point_2m:K</th>\n",
       "      <th>diffuse_rad:W</th>\n",
       "      <th>diffuse_rad_1h:J</th>\n",
       "      <th>...</th>\n",
       "      <th>wind_speed_10m:ms</th>\n",
       "      <th>wind_speed_u_10m:ms</th>\n",
       "      <th>wind_speed_v_10m:ms</th>\n",
       "      <th>wind_speed_w_1000hPa:ms</th>\n",
       "      <th>estimated</th>\n",
       "      <th>observed</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>hour</th>\n",
       "      <th>pv_measurement</th>\n",
       "      <th>consecutive_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>31821.000000</td>\n",
       "      <td>31821.000000</td>\n",
       "      <td>25779.000000</td>\n",
       "      <td>3.182100e+04</td>\n",
       "      <td>31821.000000</td>\n",
       "      <td>29543.000000</td>\n",
       "      <td>31821.000000</td>\n",
       "      <td>31821.000000</td>\n",
       "      <td>31821.000000</td>\n",
       "      <td>3.182100e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>31821.000000</td>\n",
       "      <td>31821.000000</td>\n",
       "      <td>31821.000000</td>\n",
       "      <td>31821.000000</td>\n",
       "      <td>31821.000000</td>\n",
       "      <td>31821.000000</td>\n",
       "      <td>31821.000000</td>\n",
       "      <td>31821.000000</td>\n",
       "      <td>31845.000000</td>\n",
       "      <td>31845.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.083460</td>\n",
       "      <td>1.255892</td>\n",
       "      <td>3090.045654</td>\n",
       "      <td>5.140568e+05</td>\n",
       "      <td>142.784378</td>\n",
       "      <td>1739.221558</td>\n",
       "      <td>0.038135</td>\n",
       "      <td>275.431976</td>\n",
       "      <td>39.703842</td>\n",
       "      <td>1.429435e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>3.093539</td>\n",
       "      <td>2.363222</td>\n",
       "      <td>1.538178</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.138085</td>\n",
       "      <td>0.861915</td>\n",
       "      <td>182.842368</td>\n",
       "      <td>11.502498</td>\n",
       "      <td>603.170718</td>\n",
       "      <td>7.278411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.690561</td>\n",
       "      <td>0.036604</td>\n",
       "      <td>2619.828613</td>\n",
       "      <td>8.174113e+05</td>\n",
       "      <td>227.631027</td>\n",
       "      <td>1850.460938</td>\n",
       "      <td>0.183545</td>\n",
       "      <td>6.757713</td>\n",
       "      <td>61.189816</td>\n",
       "      <td>2.176817e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.795557</td>\n",
       "      <td>1.839440</td>\n",
       "      <td>1.191686</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>0.344995</td>\n",
       "      <td>0.344995</td>\n",
       "      <td>109.499838</td>\n",
       "      <td>6.922193</td>\n",
       "      <td>1145.868524</td>\n",
       "      <td>7.182499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.145000</td>\n",
       "      <td>27.849998</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.799999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>251.074997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.100000</td>\n",
       "      <td>1.230500</td>\n",
       "      <td>1172.037598</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>568.300049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>270.950012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.575000</td>\n",
       "      <td>1.254500</td>\n",
       "      <td>2051.600098</td>\n",
       "      <td>9.846875e+03</td>\n",
       "      <td>1.550000</td>\n",
       "      <td>1136.599976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>275.299988</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>9.894700e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>1.925000</td>\n",
       "      <td>1.275000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.760000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>1.279000</td>\n",
       "      <td>4451.049805</td>\n",
       "      <td>7.996545e+05</td>\n",
       "      <td>217.250000</td>\n",
       "      <td>2072.012451</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>280.650024</td>\n",
       "      <td>65.474998</td>\n",
       "      <td>2.348973e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>4.150000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>2.175000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>621.280000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>16.049999</td>\n",
       "      <td>1.426250</td>\n",
       "      <td>12294.901367</td>\n",
       "      <td>2.988628e+06</td>\n",
       "      <td>835.099976</td>\n",
       "      <td>11673.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>291.950012</td>\n",
       "      <td>332.274994</td>\n",
       "      <td>1.191085e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>13.275000</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>366.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>5733.420000</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       absolute_humidity_2m:gm3  air_density_2m:kgm3  ceiling_height_agl:m  \\\n",
       "count              31821.000000         31821.000000          25779.000000   \n",
       "mean                   6.083460             1.255892           3090.045654   \n",
       "std                    2.690561             0.036604           2619.828613   \n",
       "min                    0.700000             1.145000             27.849998   \n",
       "25%                    4.100000             1.230500           1172.037598   \n",
       "50%                    5.575000             1.254500           2051.600098   \n",
       "75%                    7.900000             1.279000           4451.049805   \n",
       "max                   16.049999             1.426250          12294.901367   \n",
       "\n",
       "       clear_sky_energy_1h:J  clear_sky_rad:W  cloud_base_agl:m  \\\n",
       "count           3.182100e+04     31821.000000      29543.000000   \n",
       "mean            5.140568e+05       142.784378       1739.221558   \n",
       "std             8.174113e+05       227.631027       1850.460938   \n",
       "min             0.000000e+00         0.000000         27.799999   \n",
       "25%             0.000000e+00         0.000000        568.300049   \n",
       "50%             9.846875e+03         1.550000       1136.599976   \n",
       "75%             7.996545e+05       217.250000       2072.012451   \n",
       "max             2.988628e+06       835.099976      11673.625000   \n",
       "\n",
       "       dew_or_rime:idx  dew_point_2m:K  diffuse_rad:W  diffuse_rad_1h:J  ...  \\\n",
       "count     31821.000000    31821.000000   31821.000000      3.182100e+04  ...   \n",
       "mean          0.038135      275.431976      39.703842      1.429435e+05  ...   \n",
       "std           0.183545        6.757713      61.189816      2.176817e+05  ...   \n",
       "min           0.000000      251.074997       0.000000      0.000000e+00  ...   \n",
       "25%           0.000000      270.950012       0.000000      0.000000e+00  ...   \n",
       "50%           0.000000      275.299988       0.875000      9.894700e+03  ...   \n",
       "75%           0.000000      280.650024      65.474998      2.348973e+05  ...   \n",
       "max           1.000000      291.950012     332.274994      1.191085e+06  ...   \n",
       "\n",
       "       wind_speed_10m:ms  wind_speed_u_10m:ms  wind_speed_v_10m:ms  \\\n",
       "count       31821.000000         31821.000000         31821.000000   \n",
       "mean            3.093539             2.363222             1.538178   \n",
       "std             1.795557             1.839440             1.191686   \n",
       "min             0.025000             0.000000             0.000000   \n",
       "25%             1.700000             0.950000             0.625000   \n",
       "50%             2.750000             1.925000             1.275000   \n",
       "75%             4.150000             3.400000             2.175000   \n",
       "max            13.275000            11.200000             8.400000   \n",
       "\n",
       "       wind_speed_w_1000hPa:ms     estimated      observed   day_of_year  \\\n",
       "count             31821.000000  31821.000000  31821.000000  31821.000000   \n",
       "mean                  0.000007      0.138085      0.861915    182.842368   \n",
       "std                   0.000642      0.344995      0.344995    109.499838   \n",
       "min                   0.000000      0.000000      0.000000      1.000000   \n",
       "25%                   0.000000      0.000000      1.000000     84.000000   \n",
       "50%                   0.000000      0.000000      1.000000    182.000000   \n",
       "75%                   0.000000      0.000000      1.000000    281.000000   \n",
       "max                   0.100000      1.000000      1.000000    366.000000   \n",
       "\n",
       "               hour  pv_measurement  consecutive_count  \n",
       "count  31821.000000    31845.000000       31845.000000  \n",
       "mean      11.502498      603.170718           7.278411  \n",
       "std        6.922193     1145.868524           7.182499  \n",
       "min        0.000000        0.000000           1.000000  \n",
       "25%        6.000000        0.000000           1.000000  \n",
       "50%       12.000000        1.760000           1.000000  \n",
       "75%       18.000000      621.280000          15.000000  \n",
       "max       23.000000     5733.420000          22.000000  \n",
       "\n",
       "[8 rows x 51 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = TabularDataset(df1_0)\n",
    "train2 = TabularDataset(df2_0)\n",
    "train3 = TabularDataset(df3_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning1 = TabularDataset(tune1)\n",
    "tuning2 = TabularDataset(tune2)\n",
    "tuning3 = TabularDataset(tune3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231108_075457/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231108_075457/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Thu Jun  8 22:22:20 PDT 2023; root:xnu-8796.121.3~7/RELEASE_ARM64_T6000\n",
      "Disk Space Avail:   662.91 GB / 994.66 GB (66.6%)\n",
      "Train Data Rows:    34042\n",
      "Train Data Columns: 50\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (5733.42, 0.0, 631.39124, 1166.42299)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    14515.6 MB\n",
      "\tTrain Data (Original)  Memory Usage: 7.49 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['snow_drift:idx']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['snow_drift:idx']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 48 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])   :  1 | ['consecutive_count']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 46 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', [])       :  1 | ['consecutive_count']\n",
      "\t\t('int', ['bool']) :  2 | ['elevation:m', 'snow_density:kgm3']\n",
      "\t0.8s = Fit runtime\n",
      "\t49 features in original data used to generate 49 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 7.15 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.86s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\t-266.5801\t = Validation score   (-mean_absolute_error)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t1.75s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\t-267.2941\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.71s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n"
     ]
    }
   ],
   "source": [
    "predictor1 = TabularPredictor(label=\"pv_measurement\", eval_metric='mean_absolute_error').fit(\n",
    "    train1,\n",
    "    # time_limit=6000,\n",
    "    # hyperparameters='extrme', \n",
    "    presets='best_quality',\n",
    "    tuning_data = tuning1,\n",
    "    use_bag_holdout=True,\n",
    "    # num_bag_folds= 6,\n",
    "    # refit_full = True,\n",
    "    # auto_stack = True,\n",
    "    # num_bag_sets= 10,\n",
    "    # set_best_to_refit_full= True,\n",
    "    # num_stack_levels = 2,\n",
    "    # verbosity = 3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231107_222144/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231107_222144/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Thu Jun  8 22:22:20 PDT 2023; root:xnu-8796.121.3~7/RELEASE_ARM64_T6000\n",
      "Disk Space Avail:   672.91 GB / 994.66 GB (67.7%)\n",
      "Train Data Rows:    25757\n",
      "Train Data Columns: 49\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (1152.3, 0.0, 107.69806, 212.96)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    17644.08 MB\n",
      "\tTrain Data (Original)  Memory Usage: 5.46 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['wind_speed_w_1000hPa:ms']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['wind_speed_w_1000hPa:ms']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 48 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 46 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', ['bool']) :  2 | ['elevation:m', 'snow_density:kgm3']\n",
      "\t0.3s = Fit runtime\n",
      "\t48 features in original data used to generate 48 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 5.2 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.34s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\t-41.0034\t = Validation score   (-mean_absolute_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.8s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\t-41.1236\t = Validation score   (-mean_absolute_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.69s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-22.4612\t = Validation score   (-mean_absolute_error)\n",
      "\t34.52s\t = Training   runtime\n",
      "\t60.68s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-24.087\t = Validation score   (-mean_absolute_error)\n",
      "\t43.63s\t = Training   runtime\n",
      "\t27.26s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\t-26.7704\t = Validation score   (-mean_absolute_error)\n",
      "\t17.96s\t = Training   runtime\n",
      "\t0.82s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-24.631\t = Validation score   (-mean_absolute_error)\n",
      "\t317.24s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "\t-26.4365\t = Validation score   (-mean_absolute_error)\n",
      "\t4.46s\t = Training   runtime\n",
      "\t0.71s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-27.3736\t = Validation score   (-mean_absolute_error)\n",
      "\t27.74s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-25.3677\t = Validation score   (-mean_absolute_error)\n",
      "\t129.47s\t = Training   runtime\n",
      "\t39.77s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-25.4843\t = Validation score   (-mean_absolute_error)\n",
      "\t65.44s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-23.4974\t = Validation score   (-mean_absolute_error)\n",
      "\t127.16s\t = Training   runtime\n",
      "\t105.68s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-22.1036\t = Validation score   (-mean_absolute_error)\n",
      "\t0.29s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-22.9304\t = Validation score   (-mean_absolute_error)\n",
      "\t5.3s\t = Training   runtime\n",
      "\t0.74s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-22.5327\t = Validation score   (-mean_absolute_error)\n",
      "\t3.59s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "\t-22.1909\t = Validation score   (-mean_absolute_error)\n",
      "\t38.09s\t = Training   runtime\n",
      "\t0.83s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-22.5253\t = Validation score   (-mean_absolute_error)\n",
      "\t19.91s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "\t-21.9956\t = Validation score   (-mean_absolute_error)\n",
      "\t4.57s\t = Training   runtime\n",
      "\t0.8s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-22.3851\t = Validation score   (-mean_absolute_error)\n",
      "\t19.44s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-22.3596\t = Validation score   (-mean_absolute_error)\n",
      "\t5.02s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-22.5756\t = Validation score   (-mean_absolute_error)\n",
      "\t32.18s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-22.5143\t = Validation score   (-mean_absolute_error)\n",
      "\t10.35s\t = Training   runtime\n",
      "\t0.89s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-21.7395\t = Validation score   (-mean_absolute_error)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 986.7s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231107_222144/\")\n"
     ]
    }
   ],
   "source": [
    "predictor2 = TabularPredictor(label=\"pv_measurement\", eval_metric='mean_absolute_error').fit(\n",
    "    train2,\n",
    "\n",
    "    presets='best_quality', \n",
    "    # hyperparameters='very_large', \n",
    "    # time_limit=6000,\n",
    "    tuning_data = tuning2,\n",
    "    use_bag_holdout=True,\n",
    "    # num_bag_folds= 6,\n",
    "    # refit_full = True,\n",
    "    # auto_stack = True,\n",
    "    # num_bag_sets= 10,\n",
    "    # set_best_to_refit_full= True,\n",
    "    # num_stack_levels = 2,\n",
    "    # verbosity = 3\n",
    "    )\n",
    "\n",
    "# tuning_data\n",
    "# num bag holdout 6\n",
    "# bag_holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231107_223811/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231107_223811/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Thu Jun  8 22:22:20 PDT 2023; root:xnu-8796.121.3~7/RELEASE_ARM64_T6000\n",
      "Disk Space Avail:   666.98 GB / 994.66 GB (67.1%)\n",
      "Train Data Rows:    21006\n",
      "Train Data Columns: 49\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (999.6, 0.0, 96.28227, 179.86981)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    17176.1 MB\n",
      "\tTrain Data (Original)  Memory Usage: 4.45 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['snow_drift:idx']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['snow_drift:idx']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 48 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 46 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', ['bool']) :  2 | ['elevation:m', 'snow_density:kgm3']\n",
      "\t0.2s = Fit runtime\n",
      "\t48 features in original data used to generate 48 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 4.24 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.34s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\t-32.7717\t = Validation score   (-mean_absolute_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\t-32.7852\t = Validation score   (-mean_absolute_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-19.8062\t = Validation score   (-mean_absolute_error)\n",
      "\t36.08s\t = Training   runtime\n",
      "\t52.14s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-20.8409\t = Validation score   (-mean_absolute_error)\n",
      "\t45.31s\t = Training   runtime\n",
      "\t43.3s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\t-23.6407\t = Validation score   (-mean_absolute_error)\n",
      "\t13.72s\t = Training   runtime\n",
      "\t0.56s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-21.3898\t = Validation score   (-mean_absolute_error)\n",
      "\t240.6s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "\t-23.3325\t = Validation score   (-mean_absolute_error)\n",
      "\t1.78s\t = Training   runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-23.475\t = Validation score   (-mean_absolute_error)\n",
      "\t10.34s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-22.0623\t = Validation score   (-mean_absolute_error)\n",
      "\t79.63s\t = Training   runtime\n",
      "\t29.72s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-22.1377\t = Validation score   (-mean_absolute_error)\n",
      "\t25.28s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-20.7111\t = Validation score   (-mean_absolute_error)\n",
      "\t76.41s\t = Training   runtime\n",
      "\t103.61s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-19.4662\t = Validation score   (-mean_absolute_error)\n",
      "\t0.44s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-20.3067\t = Validation score   (-mean_absolute_error)\n",
      "\t1.53s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-20.023\t = Validation score   (-mean_absolute_error)\n",
      "\t2.49s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "\t-19.6579\t = Validation score   (-mean_absolute_error)\n",
      "\t14.23s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-20.055\t = Validation score   (-mean_absolute_error)\n",
      "\t9.7s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "\t-19.4908\t = Validation score   (-mean_absolute_error)\n",
      "\t2.31s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-19.8151\t = Validation score   (-mean_absolute_error)\n",
      "\t10.39s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-19.7678\t = Validation score   (-mean_absolute_error)\n",
      "\t3.36s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-19.8984\t = Validation score   (-mean_absolute_error)\n",
      "\t19.85s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-20.0888\t = Validation score   (-mean_absolute_error)\n",
      "\t5.73s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-19.2777\t = Validation score   (-mean_absolute_error)\n",
      "\t0.27s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 665.77s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231107_223811/\")\n"
     ]
    }
   ],
   "source": [
    "predictor3 = TabularPredictor(label=\"pv_measurement\", eval_metric='mean_absolute_error' ).fit(\n",
    "    train3,\n",
    "\n",
    "    presets='best_quality', \n",
    "    # hyperparameters='very_large', \n",
    "    # time_limit=6000,\n",
    "    tuning_data = tuning3,\n",
    "    use_bag_holdout=True,\n",
    "    # num_bag_folds= 6,\n",
    "    # refit_full = True,\n",
    "    # auto_stack = True,\n",
    "    # num_bag_sets= 10,\n",
    "    # set_best_to_refit_full= True,\n",
    "    # num_stack_levels = 2,\n",
    "    # verbosity = 3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = pipin.get_test_data(\"A\")\n",
    "test2 = pipin.get_test_data(\"B\")\n",
    "test3 = pipin.get_test_data(\"C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data1 = TabularDataset(test1)\n",
    "test_data2 = TabularDataset(test2)\n",
    "test_data3 = TabularDataset(test3)\n",
    "\n",
    "pred1 = pd.DataFrame(predictor1.predict(test_data1))\n",
    "pred2 = pd.DataFrame(predictor2.predict(test_data2))\n",
    "pred3 = pd.DataFrame(predictor3.predict(test_data3))\n",
    "\n",
    "negatives_pred1 = pred1[pred1[\"pv_measurement\"] < 0]\n",
    "negatives_pred2 = pred2[pred2[\"pv_measurement\"] < 0]\n",
    "negatives_pred3 = pred3[pred3[\"pv_measurement\"] < 0]\n",
    "neg = pd.concat([negatives_pred1, negatives_pred2, negatives_pred3])\n",
    "neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_unique_filename\n",
    "pred = pd.concat([pred1, pred2, pred3])\n",
    "final_prediction = pipin.post_processing(pred, prediction_column=\"pv_measurement\")\n",
    "final_prediction.to_csv(get_unique_filename('gluon_3_same_as_145'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.26821113427386"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = pipin.compare_mae(final_prediction)\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor.evaluate(df1, silent=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gluon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
